{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34141,
     "status": "ok",
     "timestamp": 1691905085317,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "7tRn1aPk-Dh1",
    "outputId": "f3b163a0-bef9-4bc4-8d95-2725c8a4d31d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "software-properties-common is already the newest version (0.99.22.7).\n",
      "The following additional packages will be installed:\n",
      "  libegl-dev libgl-dev libgles-dev libgles1 libglu1-mesa libglu1-mesa-dev\n",
      "  libglvnd-core-dev libglvnd-dev libglx-dev libopengl-dev libosmesa6\n",
      "The following NEW packages will be installed:\n",
      "  libegl-dev libgl-dev libgl1-mesa-dev libgl1-mesa-glx libgles-dev libgles1\n",
      "  libglew-dev libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev\n",
      "  libglx-dev libopengl-dev libosmesa6 libosmesa6-dev\n",
      "0 upgraded, 15 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 3,952 kB of archives.\n",
      "After this operation, 18.7 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libgl1-mesa-glx amd64 23.0.4-0ubuntu1~22.04.1 [5,584 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libglew-dev amd64 2.2.0-4 [287 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6 amd64 23.0.4-0ubuntu1~22.04.1 [3,054 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libosmesa6-dev amd64 23.0.4-0ubuntu1~22.04.1 [8,986 B]\n",
      "Fetched 3,952 kB in 0s (23.5 MB/s)\n",
      "Selecting previously unselected package libglx-dev:amd64.\n",
      "(Reading database ... 120828 files and directories currently installed.)\n",
      "Preparing to unpack .../00-libglx-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl-dev:amd64.\n",
      "Preparing to unpack .../01-libgl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libegl-dev:amd64.\n",
      "Preparing to unpack .../02-libegl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
      "Preparing to unpack .../03-libgl1-mesa-glx_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libgles1:amd64.\n",
      "Preparing to unpack .../04-libgles1_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgles-dev:amd64.\n",
      "Preparing to unpack .../05-libgles-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
      "Preparing to unpack .../06-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libopengl-dev:amd64.\n",
      "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libglvnd-dev:amd64.\n",
      "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
      "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
      "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
      "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libglu1-mesa:amd64.\n",
      "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
      "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
      "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
      "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
      "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
      "Selecting previously unselected package libglew-dev:amd64.\n",
      "Preparing to unpack .../12-libglew-dev_2.2.0-4_amd64.deb ...\n",
      "Unpacking libglew-dev:amd64 (2.2.0-4) ...\n",
      "Selecting previously unselected package libosmesa6:amd64.\n",
      "Preparing to unpack .../13-libosmesa6_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libosmesa6:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Selecting previously unselected package libosmesa6-dev:amd64.\n",
      "Preparing to unpack .../14-libosmesa6-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
      "Unpacking libosmesa6-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libgles1:amd64 (1.4.0-1) ...\n",
      "Setting up libgl1-mesa-glx:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
      "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libosmesa6:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
      "Setting up libosmesa6-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
      "Setting up libglew-dev:amd64 (2.2.0-4) ...\n",
      "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
      "\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  patchelf\n",
      "0 upgraded, 1 newly installed, 0 to remove and 16 not upgraded.\n",
      "Need to get 72.1 kB of archives.\n",
      "After this operation, 186 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 patchelf amd64 0.14.3-1 [72.1 kB]\n",
      "Fetched 72.1 kB in 0s (1,109 kB/s)\n",
      "Selecting previously unselected package patchelf.\n",
      "(Reading database ... 120968 files and directories currently installed.)\n",
      "Preparing to unpack .../patchelf_0.14.3-1_amd64.deb ...\n",
      "Unpacking patchelf (0.14.3-1) ...\n",
      "Setting up patchelf (0.14.3-1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
      "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [857 kB]\n",
      "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [979 kB]\n",
      "Get:10 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [832 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,102 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,236 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [872 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [49.8 kB]\n",
      "Hit:15 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:16 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:18 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,165 kB]\n",
      "Get:19 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,111 kB]\n",
      "Fetched 9,562 kB in 3s (2,877 kB/s)\n",
      "Reading package lists... Done\n",
      "Collecting stable-baselines3\n",
      "  Downloading stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.4/178.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gymnasium==0.28.1 (from stable-baselines3)\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.0.1+cu118)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (2.2.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (1.5.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3) (3.7.1)\n",
      "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1->stable-baselines3)\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1->stable-baselines3) (4.7.1)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium==0.28.1->stable-baselines3)\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->stable-baselines3) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (3.27.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11->stable-baselines3) (16.0.6)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->stable-baselines3) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->stable-baselines3) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11->stable-baselines3) (1.3.0)\n",
      "Installing collected packages: farama-notifications, jax-jumpy, gymnasium, stable-baselines3\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0 stable-baselines3-2.0.0\n",
      "Collecting mujoco\n",
      "  Downloading mujoco-2.3.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.4.0)\n",
      "Collecting glfw (from mujoco)\n",
      "  Downloading glfw-2.6.2-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (208 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.2/208.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mujoco) (1.23.5)\n",
      "Requirement already satisfied: pyopengl in /usr/local/lib/python3.10/dist-packages (from mujoco) (3.1.7)\n",
      "Installing collected packages: glfw, mujoco\n",
      "Successfully installed glfw-2.6.2 mujoco-2.3.7\n",
      "Collecting gymnasium==0.29\n",
      "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29) (4.7.1)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.29) (0.0.4)\n",
      "Installing collected packages: gymnasium\n",
      "  Attempting uninstall: gymnasium\n",
      "    Found existing installation: gymnasium 0.28.1\n",
      "    Uninstalling gymnasium-0.28.1:\n",
      "      Successfully uninstalled gymnasium-0.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "stable-baselines3 2.0.0 requires gymnasium==0.28.1, but you have gymnasium 0.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gymnasium-0.29.0\n",
      "Collecting free-mujoco-py\n",
      "  Downloading free_mujoco_py-2.1.6-py3-none-any.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Cython<0.30.0,>=0.29.24 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (0.29.36)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.15.1)\n",
      "Collecting fasteners==0.15 (from free-mujoco-py)\n",
      "  Downloading fasteners-0.15-py2.py3-none-any.whl (23 kB)\n",
      "Collecting glfw<2.0.0,>=1.4.0 (from free-mujoco-py)\n",
      "  Downloading glfw-1.12.0-py2.py27.py3.py30.py31.py32.py33.py34.py35.py36.py37.py38-none-manylinux2014_x86_64.whl (203 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.7/203.7 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: imageio<3.0.0,>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (2.31.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.21.3 in /usr/local/lib/python3.10/dist-packages (from free-mujoco-py) (1.23.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fasteners==0.15->free-mujoco-py) (1.16.0)\n",
      "Collecting monotonic>=0.1 (from fasteners==0.15->free-mujoco-py)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi<2.0.0,>=1.15.0->free-mujoco-py) (2.21)\n",
      "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0.0,>=2.9.0->free-mujoco-py) (9.4.0)\n",
      "Installing collected packages: monotonic, glfw, fasteners, free-mujoco-py\n",
      "  Attempting uninstall: glfw\n",
      "    Found existing installation: glfw 2.6.2\n",
      "    Uninstalling glfw-2.6.2:\n",
      "      Successfully uninstalled glfw-2.6.2\n",
      "Successfully installed fasteners-0.15 free-mujoco-py-2.1.6 glfw-1.12.0 monotonic-1.6\n"
     ]
    }
   ],
   "source": [
    "# !apt-get install -y \\\n",
    "#     libgl1-mesa-dev \\\n",
    "#     libgl1-mesa-glx \\\n",
    "#     libglew-dev \\\n",
    "#     libosmesa6-dev \\\n",
    "#     software-properties-common\n",
    "\n",
    "# !apt-get install -y patchelf\n",
    "\n",
    "# !apt-get update --fix-missing\n",
    "# !pip install stable-baselines3\n",
    "# !pip install mujoco\n",
    "# !pip install  --upgrade gymnasium==0.29\n",
    "# !pip install free-mujoco-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11664,
     "status": "ok",
     "timestamp": 1691905096977,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "6lU7PTtNByzD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stable_baselines3.common.buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1691905096978,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "GowOd8RYC4dD",
    "outputId": "732af421-7710-4246-e343-3186203de804"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        if capture_video and idx == 0:\n",
    "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1691927262582,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "CTrICj0UENAS",
    "outputId": "7ad7a10f-7380-4320-dd8b-cc044076043e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class SoftQNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.array(env.single_observation_space.shape).prod() + np.prod(env.single_action_space.shape), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        x = torch.cat([x,a], 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1691927232996,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "R-sODKbuG4F0",
    "outputId": "e2d2aa14-0037-4273-aab8-21b8576ef7aa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.array(env.observation_space.shape).prod(), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_mean = nn.Linear(256, np.prod(env.single_action_space.shape))\n",
    "        self.fc_logstd = nn.Linear(256, np.prod(env.single_action_space.shape))\n",
    "        self.log_std_min = -5\n",
    "        self.log_std_max = 2\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((env.action_space.high - env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((env.action_space.high - env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        mean = self.fc_mean(x)\n",
    "        log_std = self.fc_logstd(x)\n",
    "        log_std = torch.tanh(log_std)\n",
    "        log_std = self.log_std_min + 0.5 *  (self.log_std_max - self.log_std_min) * ( log_std + 1)\n",
    "        return mean, log_std\n",
    "\n",
    "    def get_actions(self, x):\n",
    "        mean, log_std = self.forward(x)\n",
    "        std = log_std.exp()\n",
    "        normal = torch.distributions.Normal(mean, std)\n",
    "        x_t = normal.rsample()\n",
    "        y_t = torch.tanh(x_t)\n",
    "        action = y_t * self.action_scale + self.action_bias\n",
    "        log_prob = normal.log_prob(x_t)\n",
    "        log_prob -= torch.log( self.action_scale * (1 - y_t.pow(2)) + 1e-6)\n",
    "        log_prob = log_prob.sum(1, keepdim=True)\n",
    "        mean = torch.tanh(mean) * self.action_scale + self.action_bias\n",
    "        return action, log_prob, mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-20T05:25:26.843233Z",
     "iopub.status.busy": "2023-11-20T05:25:26.842889Z",
     "iopub.status.idle": "2023-11-20T05:25:26.871265Z",
     "shell.execute_reply": "2023-11-20T05:25:26.870035Z",
     "shell.execute_reply.started": "2023-11-20T05:25:26.843205Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691927562615,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "kVqwDWbhwyxG",
    "outputId": "70cab94a-7ca3-4ee9-e5f4-6d98f73d2253"
   },
   "outputs": [],
   "source": [
    "def train(env_id,\n",
    "          seed,\n",
    "          total_timesteps,\n",
    "          buffer_size,\n",
    "          gamma,\n",
    "          tau,\n",
    "          batch_size,\n",
    "          learning_starts,\n",
    "          policy_lr,\n",
    "          q_lr,\n",
    "          policy_frequency,\n",
    "          target_network_frequency,\n",
    "          noise_clip,\n",
    "          alpha):\n",
    "\n",
    "    run_name = f\"{env_id}__{seed}__{int(time.time())}\"\n",
    "    wandb.init(\n",
    "        project=\"sac-mujoco-benchmark\",\n",
    "        config={\n",
    "            \"env\":env_id,\n",
    "            \"seed\":seed,\n",
    "            \"timesteps\":total_timesteps,\n",
    "            \"buffer_size\":buffer_size,\n",
    "            \"gamma\":gamma,\n",
    "            \"tau\":tau,\n",
    "            \"batch_size\":batch_size,\n",
    "            \"learning_starts\":learning_starts,\n",
    "            \"policy_lr\":policy_lr,\n",
    "            \"q_lr\",q_lr,\n",
    "            \"policy_frequency\":policy_frequency,\n",
    "            \"target_network_frequency\":target_network_frequency,\n",
    "            \"noise_clip\":noise_clip,\n",
    "            \"alpha\":alpha,\n",
    "        },\n",
    "        sync_tensorboard=True,\n",
    "        monitor_gym=True,\n",
    "        name=run_name\n",
    "    )\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    envs = gym.vector.SyncVectorEnv([make_env(env_id, seed, 0, True, run_name)])\n",
    "\n",
    "    max_action = float(envs.single_action_space.high[0])\n",
    "\n",
    "    actor = Actor(envs).to(device)\n",
    "    qf1 = SoftQNetwork(envs).to(device)\n",
    "    qf2 = SoftQNetwork(envs).to(device)\n",
    "    qf1_target = SoftQNetwork(envs).to(device)\n",
    "    qf2_target = SoftQNetwork(envs).to(device)\n",
    "    qf1_target.load_state_dict(qf1.state_dict())\n",
    "    qf2_target.load_state_dict(qf2.state_dict())\n",
    "    q_optimiser = optim.Adam(list(qf1.parameters()) + list(qf2.parameters()), lr=q_lr)\n",
    "    actor_optimizer = optim.Adam(actor.parameters(), lr=policy_lr)\n",
    "\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "    rb = ReplayBuffer(\n",
    "        buffer_size,\n",
    "        envs.single_observation_space,\n",
    "        envs.single_action_space,\n",
    "        device,\n",
    "        handle_timeout_termination=False,\n",
    "    )\n",
    "\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    obs,_ = envs.reset(seed=seed)\n",
    "    for global_step in range(total_timesteps):\n",
    "        if global_step < learning_starts:\n",
    "            actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "        else:\n",
    "            actions, _, _ = actor.get_actions(torch.Tensor(obs).to(device))\n",
    "            actions = actions.detach().cpu().numpy()\n",
    "\n",
    "        next_obs, rewards, terminated, truncated, infos = envs.step(actions)\n",
    "\n",
    "        if \"final_info\" in infos:\n",
    "            for info in infos[\"final_info\"]:\n",
    "                print(f\"global_step={global_step} episodic_return={info['episode']['r']}\")\n",
    "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "                break\n",
    "\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for idx,d in enumerate(truncated):\n",
    "            if d:\n",
    "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        rb.add(obs, real_next_obs, actions, rewards, terminated, infos)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "        if global_step > learning_starts:\n",
    "            data = rb.sample(batch_size)\n",
    "            with torch.no_grad():\n",
    "                next_state_actions, next_state_log_pi, _ = actor.get_actions(data.next_observations)\n",
    "                qf1_next_target = qf1_target(data.next_observations, next_state_actions)\n",
    "                qf2_next_target = qf2_target(data.next_observations, next_state_actions)\n",
    "                min_qf_next_target = torch.min(qf1_next_target, qf2_next_target) - alpha * next_state_log_pi\n",
    "                next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * gamma * (min_qf_next_target).view(-1)\n",
    "\n",
    "            qf1_a_values = qf1(data.observations, data.actions).view(-1)\n",
    "            qf2_a_values = qf2(data.observations, data.actions).view(-1)\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "            qf2_loss = F.mse_loss(qf2_a_values, next_q_value)\n",
    "            qf_loss = qf1_loss + qf2_loss\n",
    "\n",
    "            q_optimiser.zero_grad()\n",
    "            qf_loss.backward()\n",
    "            q_optimiser.step()\n",
    "\n",
    "            if global_step % policy_frequency == 0:\n",
    "                pi, log_pi, _ = actor.get_actions(data.observations)\n",
    "                qf1_pi = qf1(data.observations, pi)\n",
    "                qf2_pi = qf2(data.observations, pi)\n",
    "                min_qf_pi = torch.min(qf1_pi, qf2_pi).view(-1)\n",
    "                actor_loss = ((alpha * log_pi) - min_qf_pi).mean()\n",
    "\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "            if global_step % target_network_frequency == 0:\n",
    "                for param, target_param in zip(qf1.parameters(), qf1_target.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "                for param, target_param in zip(qf2.parameters(), qf2_target.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 - tau) * target_param.data)\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar(\"losses/qf1_values\", qf1_a_values.mean().item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf2_values\", qf2_a_values.mean().item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf1_loss\", qf1_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf2_loss\", qf2_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf_loss\", qf_loss.item() / 2.0, global_step)\n",
    "                writer.add_scalar(\"losses/actor_loss\", actor_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/alpha\", alpha, global_step)\n",
    "                writer.add_scalar(\"charts/SPS\", int(global_step / (time.time() - start_time)), global_step)\n",
    "\n",
    "    envs.close()\n",
    "    writer.close()\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691926875723,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "N-XatFf9rli9"
   },
   "outputs": [],
   "source": [
    "env = {\"hopper\":\"Hopper-v2\",\"humanoid\":\"Humanoid-v2\",\"halfCheetah\":\"HalfCheetah-v2\",\"ant\":\"Ant-v2\"}\n",
    "seed = 1\n",
    "total_timesteps = 500000\n",
    "policy_learning_rate = 0.0003\n",
    "q_learning_rate = 0.0001\n",
    "buffer_size = 100000\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "batch_size = 256\n",
    "exploration_noise = 0.1\n",
    "learning_starts = 50000\n",
    "policy_frequency = 2\n",
    "target_network_frequency = 1\n",
    "alpha = 0.2\n",
    "noise_clip = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 861744,
     "status": "error",
     "timestamp": 1691948677386,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "hextrzLvs4yU",
    "outputId": "eba414d4-e8ff-4439-9d2c-d545fb86a746"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:513: DeprecationWarning: \u001b[33mWARN: The environment HalfCheetah-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/mujoco/mujoco_env.py:211: DeprecationWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.is_vector_env to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_vector_env` for environment variables or `env.get_attr('is_vector_env')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/core.py:297: UserWarning: \u001b[33mWARN: env.num_envs to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.num_envs` for environment variables or `env.get_attr('num_envs')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:135: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/gymnasium/utils/passive_env_checker.py:159: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-0.mp4\n",
      "global_step=999 episodic_return=[-290.36285]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-1.mp4\n",
      "global_step=1999 episodic_return=[-265.64658]\n",
      "global_step=2999 episodic_return=[-277.56036]\n",
      "global_step=3999 episodic_return=[-177.74356]\n",
      "global_step=4999 episodic_return=[-304.93332]\n",
      "global_step=5999 episodic_return=[-218.62822]\n",
      "global_step=6999 episodic_return=[-216.49706]\n",
      "global_step=7999 episodic_return=[-349.96634]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-8.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-8.mp4\n",
      "global_step=8999 episodic_return=[-348.958]\n",
      "global_step=9999 episodic_return=[-166.24995]\n",
      "global_step=10999 episodic_return=[-198.58427]\n",
      "global_step=11999 episodic_return=[-193.47505]\n",
      "global_step=12999 episodic_return=[-117.61518]\n",
      "global_step=13999 episodic_return=[-364.74878]\n",
      "global_step=14999 episodic_return=[-171.0557]\n",
      "global_step=15999 episodic_return=[-285.139]\n",
      "global_step=16999 episodic_return=[-218.25229]\n",
      "global_step=17999 episodic_return=[-205.81152]\n",
      "global_step=18999 episodic_return=[-326.8549]\n",
      "global_step=19999 episodic_return=[-387.1138]\n",
      "global_step=20999 episodic_return=[-302.94595]\n",
      "global_step=21999 episodic_return=[-160.01483]\n",
      "global_step=22999 episodic_return=[-145.06184]\n",
      "global_step=23999 episodic_return=[-34.949318]\n",
      "global_step=24999 episodic_return=[-326.93106]\n",
      "global_step=25999 episodic_return=[-280.37436]\n",
      "global_step=26999 episodic_return=[-198.99377]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-27.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-27.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-27.mp4\n",
      "global_step=27999 episodic_return=[-269.1459]\n",
      "global_step=28999 episodic_return=[-211.94794]\n",
      "global_step=29999 episodic_return=[-324.1697]\n",
      "global_step=30999 episodic_return=[-298.2644]\n",
      "global_step=31999 episodic_return=[-222.77611]\n",
      "global_step=32999 episodic_return=[-229.46997]\n",
      "global_step=33999 episodic_return=[-290.52527]\n",
      "global_step=34999 episodic_return=[-243.12852]\n",
      "global_step=35999 episodic_return=[-337.54956]\n",
      "global_step=36999 episodic_return=[-328.91647]\n",
      "global_step=37999 episodic_return=[-256.67102]\n",
      "global_step=38999 episodic_return=[-268.15323]\n",
      "global_step=39999 episodic_return=[-367.25827]\n",
      "global_step=40999 episodic_return=[-282.81506]\n",
      "global_step=41999 episodic_return=[-291.27274]\n",
      "global_step=42999 episodic_return=[-416.1082]\n",
      "global_step=43999 episodic_return=[-195.68433]\n",
      "global_step=44999 episodic_return=[-273.47717]\n",
      "global_step=45999 episodic_return=[-317.45792]\n",
      "global_step=46999 episodic_return=[-387.72183]\n",
      "global_step=47999 episodic_return=[-384.11777]\n",
      "global_step=48999 episodic_return=[-173.03925]\n",
      "global_step=49999 episodic_return=[-300.3021]\n",
      "global_step=50999 episodic_return=[-801.4237]\n",
      "global_step=51999 episodic_return=[-787.5227]\n",
      "global_step=52999 episodic_return=[-625.0398]\n",
      "global_step=53999 episodic_return=[-547.7291]\n",
      "global_step=54999 episodic_return=[-526.60834]\n",
      "global_step=55999 episodic_return=[-566.1828]\n",
      "global_step=56999 episodic_return=[-554.8489]\n",
      "global_step=57999 episodic_return=[-594.586]\n",
      "global_step=58999 episodic_return=[-591.71826]\n",
      "global_step=59999 episodic_return=[-574.5773]\n",
      "global_step=60999 episodic_return=[-573.9344]\n",
      "global_step=61999 episodic_return=[-605.31366]\n",
      "global_step=62999 episodic_return=[-562.853]\n",
      "global_step=63999 episodic_return=[-547.4995]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-64.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-64.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-64.mp4\n",
      "global_step=64999 episodic_return=[-527.8817]\n",
      "global_step=65999 episodic_return=[-517.5039]\n",
      "global_step=66999 episodic_return=[-517.91736]\n",
      "global_step=67999 episodic_return=[-487.32184]\n",
      "global_step=68999 episodic_return=[-489.32846]\n",
      "global_step=69999 episodic_return=[-485.72675]\n",
      "global_step=70999 episodic_return=[-491.18024]\n",
      "global_step=71999 episodic_return=[-499.59402]\n",
      "global_step=72999 episodic_return=[-422.36078]\n",
      "global_step=73999 episodic_return=[-461.14386]\n",
      "global_step=74999 episodic_return=[-473.17523]\n",
      "global_step=75999 episodic_return=[-433.60135]\n",
      "global_step=76999 episodic_return=[-448.52777]\n",
      "global_step=77999 episodic_return=[-444.9023]\n",
      "global_step=78999 episodic_return=[-428.50986]\n",
      "global_step=79999 episodic_return=[-453.74527]\n",
      "global_step=80999 episodic_return=[-434.34912]\n",
      "global_step=81999 episodic_return=[-437.01117]\n",
      "global_step=82999 episodic_return=[-467.45078]\n",
      "global_step=83999 episodic_return=[-422.07803]\n",
      "global_step=84999 episodic_return=[-429.41806]\n",
      "global_step=85999 episodic_return=[-436.46002]\n",
      "global_step=86999 episodic_return=[-433.26746]\n",
      "global_step=87999 episodic_return=[-430.796]\n",
      "global_step=88999 episodic_return=[-456.25702]\n",
      "global_step=89999 episodic_return=[-437.48892]\n",
      "global_step=90999 episodic_return=[-426.97122]\n",
      "global_step=91999 episodic_return=[-459.74225]\n",
      "global_step=92999 episodic_return=[-410.5805]\n",
      "global_step=93999 episodic_return=[-441.75327]\n",
      "global_step=94999 episodic_return=[-437.73367]\n",
      "global_step=95999 episodic_return=[-440.99396]\n",
      "global_step=96999 episodic_return=[-425.15955]\n",
      "global_step=97999 episodic_return=[-438.2532]\n",
      "global_step=98999 episodic_return=[-409.2914]\n",
      "global_step=99999 episodic_return=[-431.32703]\n",
      "global_step=100999 episodic_return=[-412.6951]\n",
      "global_step=101999 episodic_return=[-415.29556]\n",
      "global_step=102999 episodic_return=[-420.6436]\n",
      "global_step=103999 episodic_return=[-401.26236]\n",
      "global_step=104999 episodic_return=[-407.32745]\n",
      "global_step=105999 episodic_return=[-410.9967]\n",
      "global_step=106999 episodic_return=[-399.54974]\n",
      "global_step=107999 episodic_return=[-405.3294]\n",
      "global_step=108999 episodic_return=[-406.9079]\n",
      "global_step=109999 episodic_return=[-394.6613]\n",
      "global_step=110999 episodic_return=[-392.4952]\n",
      "global_step=111999 episodic_return=[-411.99158]\n",
      "global_step=112999 episodic_return=[-399.1004]\n",
      "global_step=113999 episodic_return=[-412.93283]\n",
      "global_step=114999 episodic_return=[-384.11954]\n",
      "global_step=115999 episodic_return=[-388.53415]\n",
      "global_step=116999 episodic_return=[-393.2511]\n",
      "global_step=117999 episodic_return=[-397.4206]\n",
      "global_step=118999 episodic_return=[-401.3566]\n",
      "global_step=119999 episodic_return=[-388.0714]\n",
      "global_step=120999 episodic_return=[-390.155]\n",
      "global_step=121999 episodic_return=[-377.01495]\n",
      "global_step=122999 episodic_return=[-391.75803]\n",
      "global_step=123999 episodic_return=[-399.47748]\n",
      "global_step=124999 episodic_return=[-379.62454]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-125.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-125.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-125.mp4\n",
      "global_step=125999 episodic_return=[-376.3235]\n",
      "global_step=126999 episodic_return=[-376.86282]\n",
      "global_step=127999 episodic_return=[-366.40778]\n",
      "global_step=128999 episodic_return=[-381.72992]\n",
      "global_step=129999 episodic_return=[-382.21994]\n",
      "global_step=130999 episodic_return=[-386.13715]\n",
      "global_step=131999 episodic_return=[-375.02954]\n",
      "global_step=132999 episodic_return=[-382.4894]\n",
      "global_step=133999 episodic_return=[-382.91943]\n",
      "global_step=134999 episodic_return=[-382.70465]\n",
      "global_step=135999 episodic_return=[-375.74857]\n",
      "global_step=136999 episodic_return=[-374.56204]\n",
      "global_step=137999 episodic_return=[-345.268]\n",
      "global_step=138999 episodic_return=[-362.09613]\n",
      "global_step=139999 episodic_return=[-379.59378]\n",
      "global_step=140999 episodic_return=[-361.62286]\n",
      "global_step=141999 episodic_return=[-355.4788]\n",
      "global_step=142999 episodic_return=[-372.67386]\n",
      "global_step=143999 episodic_return=[-400.61337]\n",
      "global_step=144999 episodic_return=[-367.82635]\n",
      "global_step=145999 episodic_return=[-355.91965]\n",
      "global_step=146999 episodic_return=[-346.66776]\n",
      "global_step=147999 episodic_return=[-375.06033]\n",
      "global_step=148999 episodic_return=[-380.32907]\n",
      "global_step=149999 episodic_return=[-351.85327]\n",
      "global_step=150999 episodic_return=[-363.55698]\n",
      "global_step=151999 episodic_return=[-373.17886]\n",
      "global_step=152999 episodic_return=[-343.09677]\n",
      "global_step=153999 episodic_return=[-361.9356]\n",
      "global_step=154999 episodic_return=[-339.24908]\n",
      "global_step=155999 episodic_return=[-354.0679]\n",
      "global_step=156999 episodic_return=[-340.53622]\n",
      "global_step=157999 episodic_return=[-347.70123]\n",
      "global_step=158999 episodic_return=[-327.3295]\n",
      "global_step=159999 episodic_return=[-355.43552]\n",
      "global_step=160999 episodic_return=[-346.15347]\n",
      "global_step=161999 episodic_return=[-357.7112]\n",
      "global_step=162999 episodic_return=[-315.46475]\n",
      "global_step=163999 episodic_return=[-340.27573]\n",
      "global_step=164999 episodic_return=[-354.01553]\n",
      "global_step=165999 episodic_return=[-346.60434]\n",
      "global_step=166999 episodic_return=[-346.8752]\n",
      "global_step=167999 episodic_return=[-345.71454]\n",
      "global_step=168999 episodic_return=[-340.40375]\n",
      "global_step=169999 episodic_return=[-349.48904]\n",
      "global_step=170999 episodic_return=[-318.30917]\n",
      "global_step=171999 episodic_return=[-353.06418]\n",
      "global_step=172999 episodic_return=[-358.2967]\n",
      "global_step=173999 episodic_return=[-342.56882]\n",
      "global_step=174999 episodic_return=[-316.62613]\n",
      "global_step=175999 episodic_return=[-343.63052]\n",
      "global_step=176999 episodic_return=[-328.58188]\n",
      "global_step=177999 episodic_return=[-354.13556]\n",
      "global_step=178999 episodic_return=[-349.5181]\n",
      "global_step=179999 episodic_return=[-335.0619]\n",
      "global_step=180999 episodic_return=[-335.7454]\n",
      "global_step=181999 episodic_return=[-324.70343]\n",
      "global_step=182999 episodic_return=[-349.7698]\n",
      "global_step=183999 episodic_return=[-335.09543]\n",
      "global_step=184999 episodic_return=[-318.4444]\n",
      "global_step=185999 episodic_return=[-332.95935]\n",
      "global_step=186999 episodic_return=[-313.2594]\n",
      "global_step=187999 episodic_return=[-328.52597]\n",
      "global_step=188999 episodic_return=[-317.41763]\n",
      "global_step=189999 episodic_return=[-334.14948]\n",
      "global_step=190999 episodic_return=[-318.3603]\n",
      "global_step=191999 episodic_return=[-336.56158]\n",
      "global_step=192999 episodic_return=[-312.05344]\n",
      "global_step=193999 episodic_return=[-344.19818]\n",
      "global_step=194999 episodic_return=[-328.01334]\n",
      "global_step=195999 episodic_return=[-351.61703]\n",
      "global_step=196999 episodic_return=[-334.74612]\n",
      "global_step=197999 episodic_return=[-331.04422]\n",
      "global_step=198999 episodic_return=[-318.68292]\n",
      "global_step=199999 episodic_return=[-315.98727]\n",
      "global_step=200999 episodic_return=[-307.58163]\n",
      "global_step=201999 episodic_return=[-338.16403]\n",
      "global_step=202999 episodic_return=[-306.5939]\n",
      "global_step=203999 episodic_return=[-313.6024]\n",
      "global_step=204999 episodic_return=[-327.78485]\n",
      "global_step=205999 episodic_return=[-315.9673]\n",
      "global_step=206999 episodic_return=[-333.31238]\n",
      "global_step=207999 episodic_return=[-336.039]\n",
      "global_step=208999 episodic_return=[-340.0017]\n",
      "global_step=209999 episodic_return=[-314.7859]\n",
      "global_step=210999 episodic_return=[-328.29578]\n",
      "global_step=211999 episodic_return=[-292.1867]\n",
      "global_step=212999 episodic_return=[-318.21683]\n",
      "global_step=213999 episodic_return=[-346.39862]\n",
      "global_step=214999 episodic_return=[-306.17484]\n",
      "global_step=215999 episodic_return=[-313.9586]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-216.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-216.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-216.mp4\n",
      "global_step=216999 episodic_return=[-316.0373]\n",
      "global_step=217999 episodic_return=[-321.3237]\n",
      "global_step=218999 episodic_return=[-303.06613]\n",
      "global_step=219999 episodic_return=[-315.2012]\n",
      "global_step=220999 episodic_return=[-328.48187]\n",
      "global_step=221999 episodic_return=[-331.32974]\n",
      "global_step=222999 episodic_return=[-305.25485]\n",
      "global_step=223999 episodic_return=[-283.40903]\n",
      "global_step=224999 episodic_return=[-332.05267]\n",
      "global_step=225999 episodic_return=[-295.77548]\n",
      "global_step=226999 episodic_return=[-333.07455]\n",
      "global_step=227999 episodic_return=[-293.27646]\n",
      "global_step=228999 episodic_return=[-286.24738]\n",
      "global_step=229999 episodic_return=[-322.3173]\n",
      "global_step=230999 episodic_return=[-300.1896]\n",
      "global_step=231999 episodic_return=[-291.33475]\n",
      "global_step=232999 episodic_return=[-308.9093]\n",
      "global_step=233999 episodic_return=[-282.49658]\n",
      "global_step=234999 episodic_return=[-282.66998]\n",
      "global_step=235999 episodic_return=[-301.7213]\n",
      "global_step=236999 episodic_return=[-288.307]\n",
      "global_step=237999 episodic_return=[-304.13132]\n",
      "global_step=238999 episodic_return=[-299.01855]\n",
      "global_step=239999 episodic_return=[-308.98267]\n",
      "global_step=240999 episodic_return=[-291.7945]\n",
      "global_step=241999 episodic_return=[-311.19504]\n",
      "global_step=242999 episodic_return=[-280.7618]\n",
      "global_step=243999 episodic_return=[-310.52896]\n",
      "global_step=244999 episodic_return=[-306.0392]\n",
      "global_step=245999 episodic_return=[-287.93903]\n",
      "global_step=246999 episodic_return=[-298.10394]\n",
      "global_step=247999 episodic_return=[-309.69675]\n",
      "global_step=248999 episodic_return=[-273.24307]\n",
      "global_step=249999 episodic_return=[-290.77557]\n",
      "global_step=250999 episodic_return=[-303.04532]\n",
      "global_step=251999 episodic_return=[-297.9314]\n",
      "global_step=252999 episodic_return=[-293.79877]\n",
      "global_step=253999 episodic_return=[-285.31467]\n",
      "global_step=254999 episodic_return=[-297.72787]\n",
      "global_step=255999 episodic_return=[-286.6454]\n",
      "global_step=256999 episodic_return=[-295.45724]\n",
      "global_step=257999 episodic_return=[-292.34613]\n",
      "global_step=258999 episodic_return=[-296.6216]\n",
      "global_step=259999 episodic_return=[-283.14786]\n",
      "global_step=260999 episodic_return=[-298.79132]\n",
      "global_step=261999 episodic_return=[-260.92407]\n",
      "global_step=262999 episodic_return=[-266.30667]\n",
      "global_step=263999 episodic_return=[-279.17554]\n",
      "global_step=264999 episodic_return=[-326.71295]\n",
      "global_step=265999 episodic_return=[-272.38757]\n",
      "global_step=266999 episodic_return=[-299.08267]\n",
      "global_step=267999 episodic_return=[-302.29932]\n",
      "global_step=268999 episodic_return=[-293.27655]\n",
      "global_step=269999 episodic_return=[-292.5695]\n",
      "global_step=270999 episodic_return=[-312.68518]\n",
      "global_step=271999 episodic_return=[-263.30136]\n",
      "global_step=272999 episodic_return=[-302.5454]\n",
      "global_step=273999 episodic_return=[-278.96167]\n",
      "global_step=274999 episodic_return=[-285.1667]\n",
      "global_step=275999 episodic_return=[-265.87866]\n",
      "global_step=276999 episodic_return=[-287.53204]\n",
      "global_step=277999 episodic_return=[-287.856]\n",
      "global_step=278999 episodic_return=[-262.90417]\n",
      "global_step=279999 episodic_return=[-287.55908]\n",
      "global_step=280999 episodic_return=[-282.04825]\n",
      "global_step=281999 episodic_return=[-279.60632]\n",
      "global_step=282999 episodic_return=[-301.66013]\n",
      "global_step=283999 episodic_return=[-284.01602]\n",
      "global_step=284999 episodic_return=[-259.52274]\n",
      "global_step=285999 episodic_return=[-268.45126]\n",
      "global_step=286999 episodic_return=[-269.81836]\n",
      "global_step=287999 episodic_return=[-241.51215]\n",
      "global_step=288999 episodic_return=[-282.4738]\n",
      "global_step=289999 episodic_return=[-272.83005]\n",
      "global_step=290999 episodic_return=[-271.80807]\n",
      "global_step=291999 episodic_return=[-263.64792]\n",
      "global_step=292999 episodic_return=[-184.25783]\n",
      "global_step=293999 episodic_return=[-262.6935]\n",
      "global_step=294999 episodic_return=[-262.51898]\n",
      "global_step=295999 episodic_return=[-292.0203]\n",
      "global_step=296999 episodic_return=[-212.3263]\n",
      "global_step=297999 episodic_return=[-238.83797]\n",
      "global_step=298999 episodic_return=[-221.47702]\n",
      "global_step=299999 episodic_return=[-226.8357]\n",
      "global_step=300999 episodic_return=[-255.60304]\n",
      "global_step=301999 episodic_return=[-185.13297]\n",
      "global_step=302999 episodic_return=[-266.5299]\n",
      "global_step=303999 episodic_return=[-281.06766]\n",
      "global_step=304999 episodic_return=[-255.38208]\n",
      "global_step=305999 episodic_return=[-165.72998]\n",
      "global_step=306999 episodic_return=[-267.77057]\n",
      "global_step=307999 episodic_return=[-251.57]\n",
      "global_step=308999 episodic_return=[-229.74727]\n",
      "global_step=309999 episodic_return=[-248.73483]\n",
      "global_step=310999 episodic_return=[-257.1599]\n",
      "global_step=311999 episodic_return=[-261.5273]\n",
      "global_step=312999 episodic_return=[-283.77585]\n",
      "global_step=313999 episodic_return=[-125.09741]\n",
      "global_step=314999 episodic_return=[-253.47945]\n",
      "global_step=315999 episodic_return=[-245.09848]\n",
      "global_step=316999 episodic_return=[-251.5206]\n",
      "global_step=317999 episodic_return=[-252.60704]\n",
      "global_step=318999 episodic_return=[-230.38849]\n",
      "global_step=319999 episodic_return=[-252.54149]\n",
      "global_step=320999 episodic_return=[-204.97638]\n",
      "global_step=321999 episodic_return=[-161.19327]\n",
      "global_step=322999 episodic_return=[-182.76001]\n",
      "global_step=323999 episodic_return=[104.363396]\n",
      "global_step=324999 episodic_return=[280.25613]\n",
      "global_step=325999 episodic_return=[29.96655]\n",
      "global_step=326999 episodic_return=[-257.46765]\n",
      "global_step=327999 episodic_return=[-177.41441]\n",
      "global_step=328999 episodic_return=[-208.68536]\n",
      "global_step=329999 episodic_return=[-249.59207]\n",
      "global_step=330999 episodic_return=[361.84613]\n",
      "global_step=331999 episodic_return=[426.56958]\n",
      "global_step=332999 episodic_return=[58.716442]\n",
      "global_step=333999 episodic_return=[-63.45842]\n",
      "global_step=334999 episodic_return=[-69.92754]\n",
      "global_step=335999 episodic_return=[156.21805]\n",
      "global_step=336999 episodic_return=[237.19408]\n",
      "global_step=337999 episodic_return=[541.5929]\n",
      "global_step=338999 episodic_return=[248.0791]\n",
      "global_step=339999 episodic_return=[540.46423]\n",
      "global_step=340999 episodic_return=[-233.45775]\n",
      "global_step=341999 episodic_return=[114.370125]\n",
      "global_step=342999 episodic_return=[552.0469]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-343.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-343.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-343.mp4\n",
      "global_step=343999 episodic_return=[679.85645]\n",
      "global_step=344999 episodic_return=[514.1515]\n",
      "global_step=345999 episodic_return=[681.74585]\n",
      "global_step=346999 episodic_return=[771.13873]\n",
      "global_step=347999 episodic_return=[779.39874]\n",
      "global_step=348999 episodic_return=[795.208]\n",
      "global_step=349999 episodic_return=[396.26105]\n",
      "global_step=350999 episodic_return=[769.7005]\n",
      "global_step=351999 episodic_return=[887.06036]\n",
      "global_step=352999 episodic_return=[625.3501]\n",
      "global_step=353999 episodic_return=[933.1343]\n",
      "global_step=354999 episodic_return=[441.64984]\n",
      "global_step=355999 episodic_return=[1071.3202]\n",
      "global_step=356999 episodic_return=[1030.1238]\n",
      "global_step=357999 episodic_return=[1083.3474]\n",
      "global_step=358999 episodic_return=[955.9901]\n",
      "global_step=359999 episodic_return=[1111.9424]\n",
      "global_step=360999 episodic_return=[1115.705]\n",
      "global_step=361999 episodic_return=[1046.1641]\n",
      "global_step=362999 episodic_return=[1119.6437]\n",
      "global_step=363999 episodic_return=[1174.2535]\n",
      "global_step=364999 episodic_return=[1129.5225]\n",
      "global_step=365999 episodic_return=[1133.0481]\n",
      "global_step=366999 episodic_return=[1227.4772]\n",
      "global_step=367999 episodic_return=[1265.7787]\n",
      "global_step=368999 episodic_return=[1247.6993]\n",
      "global_step=369999 episodic_return=[1178.0851]\n",
      "global_step=370999 episodic_return=[1357.1277]\n",
      "global_step=371999 episodic_return=[1241.589]\n",
      "global_step=372999 episodic_return=[1297.953]\n",
      "global_step=373999 episodic_return=[1174.0669]\n",
      "global_step=374999 episodic_return=[1424.0944]\n",
      "global_step=375999 episodic_return=[1433.8641]\n",
      "global_step=376999 episodic_return=[1347.9827]\n",
      "global_step=377999 episodic_return=[1332.1792]\n",
      "global_step=378999 episodic_return=[1411.7465]\n",
      "global_step=379999 episodic_return=[1468.5962]\n",
      "global_step=380999 episodic_return=[1438.3916]\n",
      "global_step=381999 episodic_return=[1340.0386]\n",
      "global_step=382999 episodic_return=[1521.7234]\n",
      "global_step=383999 episodic_return=[1472.3783]\n",
      "global_step=384999 episodic_return=[1457.5964]\n",
      "global_step=385999 episodic_return=[1419.9441]\n",
      "global_step=386999 episodic_return=[1599.9012]\n",
      "global_step=387999 episodic_return=[1618.3015]\n",
      "global_step=388999 episodic_return=[1613.3162]\n",
      "global_step=389999 episodic_return=[1644.5763]\n",
      "global_step=390999 episodic_return=[1575.8988]\n",
      "global_step=391999 episodic_return=[1502.4481]\n",
      "global_step=392999 episodic_return=[1753.0073]\n",
      "global_step=393999 episodic_return=[1678.7264]\n",
      "global_step=394999 episodic_return=[1676.9004]\n",
      "global_step=395999 episodic_return=[1654.2039]\n",
      "global_step=396999 episodic_return=[1735.2168]\n",
      "global_step=397999 episodic_return=[1785.2446]\n",
      "global_step=398999 episodic_return=[1825.447]\n",
      "global_step=399999 episodic_return=[1736.0269]\n",
      "global_step=400999 episodic_return=[1663.7251]\n",
      "global_step=401999 episodic_return=[1575.1205]\n",
      "global_step=402999 episodic_return=[1618.6257]\n",
      "global_step=403999 episodic_return=[1827.9039]\n",
      "global_step=404999 episodic_return=[1835.3182]\n",
      "global_step=405999 episodic_return=[1827.2074]\n",
      "global_step=406999 episodic_return=[1803.057]\n",
      "global_step=407999 episodic_return=[1727.8073]\n",
      "global_step=408999 episodic_return=[1873.3481]\n",
      "global_step=409999 episodic_return=[1809.2329]\n",
      "global_step=410999 episodic_return=[1864.2733]\n",
      "global_step=411999 episodic_return=[1854.4774]\n",
      "global_step=412999 episodic_return=[1890.1094]\n",
      "global_step=413999 episodic_return=[1922.6107]\n",
      "global_step=414999 episodic_return=[1898.3336]\n",
      "global_step=415999 episodic_return=[1914.409]\n",
      "global_step=416999 episodic_return=[1911.8696]\n",
      "global_step=417999 episodic_return=[1928.1984]\n",
      "global_step=418999 episodic_return=[1915.7589]\n",
      "global_step=419999 episodic_return=[1914.2296]\n",
      "global_step=420999 episodic_return=[1920.102]\n",
      "global_step=421999 episodic_return=[1975.2053]\n",
      "global_step=422999 episodic_return=[1869.0759]\n",
      "global_step=423999 episodic_return=[1947.413]\n",
      "global_step=424999 episodic_return=[1976.0883]\n",
      "global_step=425999 episodic_return=[1936.2633]\n",
      "global_step=426999 episodic_return=[1939.0859]\n",
      "global_step=427999 episodic_return=[2045.5719]\n",
      "global_step=428999 episodic_return=[2009.2123]\n",
      "global_step=429999 episodic_return=[1955.515]\n",
      "global_step=430999 episodic_return=[1955.0775]\n",
      "global_step=431999 episodic_return=[1992.2345]\n",
      "global_step=432999 episodic_return=[1996.3105]\n",
      "global_step=433999 episodic_return=[1991.0237]\n",
      "global_step=434999 episodic_return=[1961.0299]\n",
      "global_step=435999 episodic_return=[2041.2374]\n",
      "global_step=436999 episodic_return=[1993.9462]\n",
      "global_step=437999 episodic_return=[2030.0973]\n",
      "global_step=438999 episodic_return=[1997.8862]\n",
      "global_step=439999 episodic_return=[2057.4434]\n",
      "global_step=440999 episodic_return=[1947.8656]\n",
      "global_step=441999 episodic_return=[2024.186]\n",
      "global_step=442999 episodic_return=[2014.3927]\n",
      "global_step=443999 episodic_return=[1948.846]\n",
      "global_step=444999 episodic_return=[2063.9104]\n",
      "global_step=445999 episodic_return=[1959.4049]\n",
      "global_step=446999 episodic_return=[2043.4331]\n",
      "global_step=447999 episodic_return=[2097.525]\n",
      "global_step=448999 episodic_return=[2123.4602]\n",
      "global_step=449999 episodic_return=[2038.8502]\n",
      "global_step=450999 episodic_return=[2071.935]\n",
      "global_step=451999 episodic_return=[2078.0066]\n",
      "global_step=452999 episodic_return=[2084.5713]\n",
      "global_step=453999 episodic_return=[2140.5874]\n",
      "global_step=454999 episodic_return=[2150.2498]\n",
      "global_step=455999 episodic_return=[2099.4949]\n",
      "global_step=456999 episodic_return=[2096.6226]\n",
      "global_step=457999 episodic_return=[2114.0347]\n",
      "global_step=458999 episodic_return=[2165.1946]\n",
      "global_step=459999 episodic_return=[2119.6284]\n",
      "global_step=460999 episodic_return=[2092.7856]\n",
      "global_step=461999 episodic_return=[2105.8281]\n",
      "global_step=462999 episodic_return=[2121.3118]\n",
      "global_step=463999 episodic_return=[2171.481]\n",
      "global_step=464999 episodic_return=[2169.8457]\n",
      "global_step=465999 episodic_return=[2151.463]\n",
      "global_step=466999 episodic_return=[2103.1785]\n",
      "global_step=467999 episodic_return=[2152.7314]\n",
      "global_step=468999 episodic_return=[2186.574]\n",
      "global_step=469999 episodic_return=[2126.1206]\n",
      "global_step=470999 episodic_return=[2112.404]\n",
      "global_step=471999 episodic_return=[2157.7358]\n",
      "global_step=472999 episodic_return=[2146.3342]\n",
      "global_step=473999 episodic_return=[2139.8176]\n",
      "global_step=474999 episodic_return=[2137.9219]\n",
      "global_step=475999 episodic_return=[2193.8704]\n",
      "global_step=476999 episodic_return=[2144.0566]\n",
      "global_step=477999 episodic_return=[2132.3538]\n",
      "global_step=478999 episodic_return=[2185.9688]\n",
      "global_step=479999 episodic_return=[2117.3262]\n",
      "global_step=480999 episodic_return=[2077.8862]\n",
      "global_step=481999 episodic_return=[2230.8496]\n",
      "global_step=482999 episodic_return=[2160.6372]\n",
      "global_step=483999 episodic_return=[2197.4739]\n",
      "global_step=484999 episodic_return=[2195.191]\n",
      "global_step=485999 episodic_return=[2178.9692]\n",
      "global_step=486999 episodic_return=[2164.3003]\n",
      "global_step=487999 episodic_return=[2160.438]\n",
      "global_step=488999 episodic_return=[2213.3833]\n",
      "global_step=489999 episodic_return=[2214.198]\n",
      "global_step=490999 episodic_return=[2175.0212]\n",
      "global_step=491999 episodic_return=[2209.411]\n",
      "global_step=492999 episodic_return=[2214.381]\n",
      "global_step=493999 episodic_return=[2173.962]\n",
      "global_step=494999 episodic_return=[2226.6367]\n",
      "global_step=495999 episodic_return=[2256.1372]\n",
      "global_step=496999 episodic_return=[2193.0015]\n",
      "global_step=497999 episodic_return=[2239.2498]\n",
      "global_step=498999 episodic_return=[2149.2717]\n",
      "global_step=499999 episodic_return=[2209.935]\n",
      "global_step=500999 episodic_return=[2217.281]\n",
      "global_step=501999 episodic_return=[2232.1072]\n",
      "global_step=502999 episodic_return=[2263.6387]\n",
      "global_step=503999 episodic_return=[2140.2407]\n",
      "global_step=504999 episodic_return=[2248.6907]\n",
      "global_step=505999 episodic_return=[2245.6113]\n",
      "global_step=506999 episodic_return=[2273.242]\n",
      "global_step=507999 episodic_return=[2232.0168]\n",
      "global_step=508999 episodic_return=[2221.8123]\n",
      "global_step=509999 episodic_return=[2222.2798]\n",
      "global_step=510999 episodic_return=[2177.8687]\n",
      "global_step=511999 episodic_return=[2257.469]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-512.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-512.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-512.mp4\n",
      "global_step=512999 episodic_return=[2204.3438]\n",
      "global_step=513999 episodic_return=[2224.696]\n",
      "global_step=514999 episodic_return=[2187.8833]\n",
      "global_step=515999 episodic_return=[2258.0798]\n",
      "global_step=516999 episodic_return=[2227.1199]\n",
      "global_step=517999 episodic_return=[2248.6084]\n",
      "global_step=518999 episodic_return=[2259.7312]\n",
      "global_step=519999 episodic_return=[2234.4626]\n",
      "global_step=520999 episodic_return=[2268.6958]\n",
      "global_step=521999 episodic_return=[2291.1252]\n",
      "global_step=522999 episodic_return=[2238.9736]\n",
      "global_step=523999 episodic_return=[2371.8618]\n",
      "global_step=524999 episodic_return=[2253.3445]\n",
      "global_step=525999 episodic_return=[2272.8533]\n",
      "global_step=526999 episodic_return=[2302.851]\n",
      "global_step=527999 episodic_return=[2235.0808]\n",
      "global_step=528999 episodic_return=[2289.522]\n",
      "global_step=529999 episodic_return=[2180.5186]\n",
      "global_step=530999 episodic_return=[2275.1746]\n",
      "global_step=531999 episodic_return=[2325.351]\n",
      "global_step=532999 episodic_return=[2317.5503]\n",
      "global_step=533999 episodic_return=[2380.9749]\n",
      "global_step=534999 episodic_return=[2261.1838]\n",
      "global_step=535999 episodic_return=[2349.0579]\n",
      "global_step=536999 episodic_return=[2347.4106]\n",
      "global_step=537999 episodic_return=[2293.023]\n",
      "global_step=538999 episodic_return=[2274.3877]\n",
      "global_step=539999 episodic_return=[2181.0332]\n",
      "global_step=540999 episodic_return=[2311.3235]\n",
      "global_step=541999 episodic_return=[2255.692]\n",
      "global_step=542999 episodic_return=[2280.4934]\n",
      "global_step=543999 episodic_return=[2321.75]\n",
      "global_step=544999 episodic_return=[2365.2312]\n",
      "global_step=545999 episodic_return=[2241.7732]\n",
      "global_step=546999 episodic_return=[2314.2012]\n",
      "global_step=547999 episodic_return=[2350.8694]\n",
      "global_step=548999 episodic_return=[2220.24]\n",
      "global_step=549999 episodic_return=[2368.7712]\n",
      "global_step=550999 episodic_return=[2287.8682]\n",
      "global_step=551999 episodic_return=[2340.1194]\n",
      "global_step=552999 episodic_return=[2289.9775]\n",
      "global_step=553999 episodic_return=[2324.5615]\n",
      "global_step=554999 episodic_return=[2306.8687]\n",
      "global_step=555999 episodic_return=[2292.2993]\n",
      "global_step=556999 episodic_return=[-353.74475]\n",
      "global_step=557999 episodic_return=[2308.9731]\n",
      "global_step=558999 episodic_return=[-418.60913]\n",
      "global_step=559999 episodic_return=[1527.1174]\n",
      "global_step=560999 episodic_return=[-455.76508]\n",
      "global_step=561999 episodic_return=[-416.5052]\n",
      "global_step=562999 episodic_return=[2367.862]\n",
      "global_step=563999 episodic_return=[2233.901]\n",
      "global_step=564999 episodic_return=[2341.6023]\n",
      "global_step=565999 episodic_return=[2301.2258]\n",
      "global_step=566999 episodic_return=[2368.0083]\n",
      "global_step=567999 episodic_return=[2356.902]\n",
      "global_step=568999 episodic_return=[2338.2832]\n",
      "global_step=569999 episodic_return=[2357.4019]\n",
      "global_step=570999 episodic_return=[2304.1775]\n",
      "global_step=571999 episodic_return=[2272.51]\n",
      "global_step=572999 episodic_return=[2366.7922]\n",
      "global_step=573999 episodic_return=[2359.887]\n",
      "global_step=574999 episodic_return=[2324.541]\n",
      "global_step=575999 episodic_return=[2329.3252]\n",
      "global_step=576999 episodic_return=[2374.4846]\n",
      "global_step=577999 episodic_return=[2326.2183]\n",
      "global_step=578999 episodic_return=[2268.9636]\n",
      "global_step=579999 episodic_return=[2436.032]\n",
      "global_step=580999 episodic_return=[2242.8335]\n",
      "global_step=581999 episodic_return=[2294.0425]\n",
      "global_step=582999 episodic_return=[2288.4314]\n",
      "global_step=583999 episodic_return=[2230.6345]\n",
      "global_step=584999 episodic_return=[2333.617]\n",
      "global_step=585999 episodic_return=[2303.0142]\n",
      "global_step=586999 episodic_return=[2260.0095]\n",
      "global_step=587999 episodic_return=[2345.474]\n",
      "global_step=588999 episodic_return=[2369.7515]\n",
      "global_step=589999 episodic_return=[2231.1626]\n",
      "global_step=590999 episodic_return=[2344.9546]\n",
      "global_step=591999 episodic_return=[2280.3083]\n",
      "global_step=592999 episodic_return=[2402.2905]\n",
      "global_step=593999 episodic_return=[2295.265]\n",
      "global_step=594999 episodic_return=[2348.6394]\n",
      "global_step=595999 episodic_return=[2360.7888]\n",
      "global_step=596999 episodic_return=[2262.5938]\n",
      "global_step=597999 episodic_return=[2342.148]\n",
      "global_step=598999 episodic_return=[2419.033]\n",
      "global_step=599999 episodic_return=[2299.6265]\n",
      "global_step=600999 episodic_return=[2282.5432]\n",
      "global_step=601999 episodic_return=[2320.7651]\n",
      "global_step=602999 episodic_return=[2310.9722]\n",
      "global_step=603999 episodic_return=[2367.352]\n",
      "global_step=604999 episodic_return=[2262.381]\n",
      "global_step=605999 episodic_return=[-673.4376]\n",
      "global_step=606999 episodic_return=[2261.3655]\n",
      "global_step=607999 episodic_return=[1642.3955]\n",
      "global_step=608999 episodic_return=[2339.0347]\n",
      "global_step=609999 episodic_return=[2304.5444]\n",
      "global_step=610999 episodic_return=[-676.1133]\n",
      "global_step=611999 episodic_return=[-691.87317]\n",
      "global_step=612999 episodic_return=[-648.69543]\n",
      "global_step=613999 episodic_return=[2279.7732]\n",
      "global_step=614999 episodic_return=[2261.8647]\n",
      "global_step=615999 episodic_return=[2228.8274]\n",
      "global_step=616999 episodic_return=[2326.0369]\n",
      "global_step=617999 episodic_return=[2265.5461]\n",
      "global_step=618999 episodic_return=[-718.286]\n",
      "global_step=619999 episodic_return=[-647.4925]\n",
      "global_step=620999 episodic_return=[2306.054]\n",
      "global_step=621999 episodic_return=[2250.2302]\n",
      "global_step=622999 episodic_return=[2245.5564]\n",
      "global_step=623999 episodic_return=[2230.3147]\n",
      "global_step=624999 episodic_return=[-706.4828]\n",
      "global_step=625999 episodic_return=[528.4577]\n",
      "global_step=626999 episodic_return=[-675.9912]\n",
      "global_step=627999 episodic_return=[-614.10675]\n",
      "global_step=628999 episodic_return=[-512.03925]\n",
      "global_step=629999 episodic_return=[2163.604]\n",
      "global_step=630999 episodic_return=[2229.2935]\n",
      "global_step=631999 episodic_return=[-624.3259]\n",
      "global_step=632999 episodic_return=[-372.27182]\n",
      "global_step=633999 episodic_return=[-760.94543]\n",
      "global_step=634999 episodic_return=[-676.7836]\n",
      "global_step=635999 episodic_return=[-597.5624]\n",
      "global_step=636999 episodic_return=[2124.937]\n",
      "global_step=637999 episodic_return=[1874.664]\n",
      "global_step=638999 episodic_return=[1891.9913]\n",
      "global_step=639999 episodic_return=[2238.4543]\n",
      "global_step=640999 episodic_return=[2175.7058]\n",
      "global_step=641999 episodic_return=[2165.7466]\n",
      "global_step=642999 episodic_return=[2225.0603]\n",
      "global_step=643999 episodic_return=[2194.6658]\n",
      "global_step=644999 episodic_return=[2074.7517]\n",
      "global_step=645999 episodic_return=[2269.0322]\n",
      "global_step=646999 episodic_return=[2233.4988]\n",
      "global_step=647999 episodic_return=[1969.1466]\n",
      "global_step=648999 episodic_return=[2288.664]\n",
      "global_step=649999 episodic_return=[2220.1472]\n",
      "global_step=650999 episodic_return=[2241.1064]\n",
      "global_step=651999 episodic_return=[2263.2468]\n",
      "global_step=652999 episodic_return=[2247.9893]\n",
      "global_step=653999 episodic_return=[2268.8687]\n",
      "global_step=654999 episodic_return=[1989.4138]\n",
      "global_step=655999 episodic_return=[2219.7476]\n",
      "global_step=656999 episodic_return=[2216.2444]\n",
      "global_step=657999 episodic_return=[2123.1108]\n",
      "global_step=658999 episodic_return=[2283.128]\n",
      "global_step=659999 episodic_return=[2278.548]\n",
      "global_step=660999 episodic_return=[2306.1384]\n",
      "global_step=661999 episodic_return=[2322.1057]\n",
      "global_step=662999 episodic_return=[2246.268]\n",
      "global_step=663999 episodic_return=[2404.645]\n",
      "global_step=664999 episodic_return=[2344.7312]\n",
      "global_step=665999 episodic_return=[2323.218]\n",
      "global_step=666999 episodic_return=[2296.6826]\n",
      "global_step=667999 episodic_return=[2297.7937]\n",
      "global_step=668999 episodic_return=[2243.2302]\n",
      "global_step=669999 episodic_return=[2247.978]\n",
      "global_step=670999 episodic_return=[2259.2026]\n",
      "global_step=671999 episodic_return=[2256.6394]\n",
      "global_step=672999 episodic_return=[2294.513]\n",
      "global_step=673999 episodic_return=[2293.469]\n",
      "global_step=674999 episodic_return=[2301.4583]\n",
      "global_step=675999 episodic_return=[2295.699]\n",
      "global_step=676999 episodic_return=[2359.5647]\n",
      "global_step=677999 episodic_return=[2367.637]\n",
      "global_step=678999 episodic_return=[2225.8025]\n",
      "global_step=679999 episodic_return=[2297.4626]\n",
      "global_step=680999 episodic_return=[2278.5537]\n",
      "global_step=681999 episodic_return=[2322.4827]\n",
      "global_step=682999 episodic_return=[2292.792]\n",
      "global_step=683999 episodic_return=[2313.75]\n",
      "global_step=684999 episodic_return=[2054.3484]\n",
      "global_step=685999 episodic_return=[2193.2437]\n",
      "global_step=686999 episodic_return=[2293.0117]\n",
      "global_step=687999 episodic_return=[2290.391]\n",
      "global_step=688999 episodic_return=[2269.015]\n",
      "global_step=689999 episodic_return=[2128.9697]\n",
      "global_step=690999 episodic_return=[2221.707]\n",
      "global_step=691999 episodic_return=[2312.3198]\n",
      "global_step=692999 episodic_return=[2342.6895]\n",
      "global_step=693999 episodic_return=[2244.8982]\n",
      "global_step=694999 episodic_return=[2220.047]\n",
      "global_step=695999 episodic_return=[2348.9905]\n",
      "global_step=696999 episodic_return=[2066.4111]\n",
      "global_step=697999 episodic_return=[2269.0195]\n",
      "global_step=698999 episodic_return=[2263.6543]\n",
      "global_step=699999 episodic_return=[2333.224]\n",
      "global_step=700999 episodic_return=[2209.1416]\n",
      "global_step=701999 episodic_return=[2335.2554]\n",
      "global_step=702999 episodic_return=[2330.35]\n",
      "global_step=703999 episodic_return=[2272.4453]\n",
      "global_step=704999 episodic_return=[2305.284]\n",
      "global_step=705999 episodic_return=[890.1563]\n",
      "global_step=706999 episodic_return=[2327.9302]\n",
      "global_step=707999 episodic_return=[2324.8286]\n",
      "global_step=708999 episodic_return=[2208.119]\n",
      "global_step=709999 episodic_return=[2256.1523]\n",
      "global_step=710999 episodic_return=[-709.4524]\n",
      "global_step=711999 episodic_return=[1204.4172]\n",
      "global_step=712999 episodic_return=[-617.9208]\n",
      "global_step=713999 episodic_return=[-595.15735]\n",
      "global_step=714999 episodic_return=[-603.18066]\n",
      "global_step=715999 episodic_return=[2280.114]\n",
      "global_step=716999 episodic_return=[1842.136]\n",
      "global_step=717999 episodic_return=[2279.627]\n",
      "global_step=718999 episodic_return=[2220.843]\n",
      "global_step=719999 episodic_return=[2219.5186]\n",
      "global_step=720999 episodic_return=[2343.63]\n",
      "global_step=721999 episodic_return=[2218.0698]\n",
      "global_step=722999 episodic_return=[2291.0955]\n",
      "global_step=723999 episodic_return=[2210.8481]\n",
      "global_step=724999 episodic_return=[2203.9114]\n",
      "global_step=725999 episodic_return=[2230.9202]\n",
      "global_step=726999 episodic_return=[2200.276]\n",
      "global_step=727999 episodic_return=[2260.2344]\n",
      "global_step=728999 episodic_return=[2294.435]\n",
      "Moviepy - Building video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-729.mp4.\n",
      "Moviepy - Writing video /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-729.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /content/videos/HalfCheetah-v2__1__1691937044/rl-video-episode-729.mp4\n",
      "global_step=729999 episodic_return=[2265.598]\n",
      "global_step=730999 episodic_return=[2237.3757]\n",
      "global_step=731999 episodic_return=[2258.6562]\n",
      "global_step=732999 episodic_return=[2355.3076]\n",
      "global_step=733999 episodic_return=[2202.4995]\n",
      "global_step=734999 episodic_return=[2349.037]\n",
      "global_step=735999 episodic_return=[2308.035]\n",
      "global_step=736999 episodic_return=[2356.153]\n",
      "global_step=737999 episodic_return=[2338.9646]\n",
      "global_step=738999 episodic_return=[2189.5933]\n",
      "global_step=739999 episodic_return=[2256.6716]\n",
      "global_step=740999 episodic_return=[2173.1855]\n",
      "global_step=741999 episodic_return=[2234.1045]\n",
      "global_step=742999 episodic_return=[2227.5483]\n",
      "global_step=743999 episodic_return=[2342.8767]\n",
      "global_step=744999 episodic_return=[2330.8066]\n",
      "global_step=745999 episodic_return=[2340.1436]\n",
      "global_step=746999 episodic_return=[2335.048]\n",
      "global_step=747999 episodic_return=[2387.3328]\n",
      "global_step=748999 episodic_return=[2308.1567]\n",
      "global_step=749999 episodic_return=[2279.8708]\n",
      "global_step=750999 episodic_return=[2364.8623]\n",
      "global_step=751999 episodic_return=[2314.7095]\n",
      "global_step=752999 episodic_return=[2401.1826]\n",
      "global_step=753999 episodic_return=[2307.906]\n",
      "global_step=754999 episodic_return=[2330.6643]\n",
      "global_step=755999 episodic_return=[2315.321]\n",
      "global_step=756999 episodic_return=[2328.481]\n",
      "global_step=757999 episodic_return=[2316.7727]\n",
      "global_step=758999 episodic_return=[2292.3647]\n",
      "global_step=759999 episodic_return=[2322.5623]\n",
      "global_step=760999 episodic_return=[2133.4282]\n",
      "global_step=761999 episodic_return=[2286.6477]\n",
      "global_step=762999 episodic_return=[2311.1082]\n",
      "global_step=763999 episodic_return=[2254.9214]\n",
      "global_step=764999 episodic_return=[2350.1733]\n",
      "global_step=765999 episodic_return=[2392.3174]\n",
      "global_step=766999 episodic_return=[2277.9631]\n",
      "global_step=767999 episodic_return=[2311.0667]\n",
      "global_step=768999 episodic_return=[2333.8223]\n",
      "global_step=769999 episodic_return=[2330.01]\n",
      "global_step=770999 episodic_return=[2383.8105]\n",
      "global_step=771999 episodic_return=[2380.351]\n",
      "global_step=772999 episodic_return=[2324.9478]\n",
      "global_step=773999 episodic_return=[2313.543]\n",
      "global_step=774999 episodic_return=[2295.039]\n",
      "global_step=775999 episodic_return=[2367.26]\n",
      "global_step=776999 episodic_return=[2332.7478]\n",
      "global_step=777999 episodic_return=[2272.6492]\n",
      "global_step=778999 episodic_return=[2421.861]\n",
      "global_step=779999 episodic_return=[2320.8828]\n",
      "global_step=780999 episodic_return=[2387.223]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f2054e4e0ab4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train(env[\"halfCheetah\"],\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mbuffer_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-ffaf12b39e45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env_id, seed, total_timesteps, buffer_size, gamma, tau, batch_size, learning_starts, policy_lr, q_lr, policy_frequency, target_network_frequency, noise_clip, alpha)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpolicy_frequency\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                 \u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_pi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m                 \u001b[0mqf1_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mqf2_pi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqf2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7b70ecfe9e25>\u001b[0m in \u001b[0;36mget_actions\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_std\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mnormal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0mx_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0my_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mbatch_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                 \u001b[0mvalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                     raise ValueError(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(env[\"halfCheetah\"],\n",
    "      seed,\n",
    "      total_timesteps,\n",
    "      buffer_size,\n",
    "      gamma,\n",
    "      tau,\n",
    "      batch_size,\n",
    "      learning_starts,\n",
    "      policy_learning_rate,\n",
    "      q_learning_rate,\n",
    "      policy_frequency,\n",
    "      target_network_frequency,\n",
    "      noise_clip,\n",
    "      alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqVxHO0mtczT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsRdhyQKU3f89Rgs3XgKs9",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
