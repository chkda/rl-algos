{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:53.333837Z",
     "iopub.status.busy": "2023-11-17T08:23:53.333434Z",
     "iopub.status.idle": "2023-11-17T08:23:53.339843Z",
     "shell.execute_reply": "2023-11-17T08:23:53.338654Z",
     "shell.execute_reply.started": "2023-11-17T08:23:53.333803Z"
    },
    "executionInfo": {
     "elapsed": 15249,
     "status": "ok",
     "timestamp": 1691651138432,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "tLEf1YUvu5i5",
    "outputId": "8d895a38-5697-46fc-e7d3-dec36f80355a"
   },
   "outputs": [],
   "source": [
    "# !apt-get install -y \\\n",
    "#     libgl1-mesa-dev \\\n",
    "#     libgl1-mesa-glx \\\n",
    "#     libglew-dev \\\n",
    "#     libosmesa6-dev \\\n",
    "#     software-properties-common\n",
    "\n",
    "# !apt-get install -y patchelf\n",
    "\n",
    "# !apt-get update --fix-missing\n",
    "# !pip install stable-baselines3\n",
    "# !pip install mujoco\n",
    "# !pip install  --upgrade gymnasium==0.29\n",
    "# !pip install free-mujoco-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:53.342583Z",
     "iopub.status.busy": "2023-11-17T08:23:53.342275Z",
     "iopub.status.idle": "2023-11-17T08:23:56.184308Z",
     "shell.execute_reply": "2023-11-17T08:23:56.183204Z",
     "shell.execute_reply.started": "2023-11-17T08:23:53.342542Z"
    },
    "id": "I6RaDB0HxvEG"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from stable_baselines3.common.buffers import ReplayBuffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:56.186082Z",
     "iopub.status.busy": "2023-11-17T08:23:56.185664Z",
     "iopub.status.idle": "2023-11-17T08:23:56.192445Z",
     "shell.execute_reply": "2023-11-17T08:23:56.191481Z",
     "shell.execute_reply.started": "2023-11-17T08:23:56.186054Z"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1691651147681,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "6AW4LvcR_f-1",
    "outputId": "03bf001c-d3fd-46fc-a212-10d0e4b0d72b"
   },
   "outputs": [],
   "source": [
    "def make_env(env_id, seed, idx, capture_video, run_name):\n",
    "    def thunk():\n",
    "        if capture_video and idx == 0 :\n",
    "            env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "            env = gym.wrappers.RecordVideo(env, f\"videos/{run_name}\")\n",
    "        else:\n",
    "            env = gym.make(env_id)\n",
    "\n",
    "        env = gym.wrappers.RecordEpisodeStatistics(env)\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        return env\n",
    "    return thunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:56.193861Z",
     "iopub.status.busy": "2023-11-17T08:23:56.193590Z",
     "iopub.status.idle": "2023-11-17T08:23:56.201294Z",
     "shell.execute_reply": "2023-11-17T08:23:56.199848Z",
     "shell.execute_reply.started": "2023-11-17T08:23:56.193834Z"
    },
    "id": "Lnlah6ghyyww"
   },
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.array(env.single_observation_space.shape).prod() + np.prod(env.single_action_space.shape), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x, a):\n",
    "        x = torch.cat([x, a], 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:56.204432Z",
     "iopub.status.busy": "2023-11-17T08:23:56.204139Z",
     "iopub.status.idle": "2023-11-17T08:23:56.214345Z",
     "shell.execute_reply": "2023-11-17T08:23:56.212634Z",
     "shell.execute_reply.started": "2023-11-17T08:23:56.204406Z"
    },
    "id": "yQykPI4x0Jk7"
   },
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "\n",
    "    def __init__(self, env):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(np.array(env.single_observation_space.shape).prod(), 256)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc_mu = nn.Linear(256, np.prod(env.single_action_space.shape))\n",
    "        self.register_buffer(\n",
    "            \"action_scale\", torch.tensor((env.action_space.high - env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "        self.register_buffer(\n",
    "            \"action_bias\", torch.tensor((env.action_space.high + env.action_space.low) / 2.0, dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.tanh(self.fc_mu(x))\n",
    "\n",
    "        return x * self.action_scale + self.action_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T08:23:56.216663Z",
     "iopub.status.busy": "2023-11-17T08:23:56.216254Z",
     "iopub.status.idle": "2023-11-17T08:23:56.238021Z",
     "shell.execute_reply": "2023-11-17T08:23:56.236713Z",
     "shell.execute_reply.started": "2023-11-17T08:23:56.216589Z"
    },
    "id": "gkUs9XGy-zRN"
   },
   "outputs": [],
   "source": [
    "def train(\n",
    "    env_id,\n",
    "    seed,\n",
    "    total_timesteps,\n",
    "    learning_rate,\n",
    "    buffer_size,\n",
    "    gamma,\n",
    "    tau,\n",
    "    batch_size,\n",
    "    exploration_noise,\n",
    "    learning_starts,\n",
    "    policy_frequency,\n",
    "    noise_clip):\n",
    "\n",
    "    run_name = f\"{env_id}__{seed}__{int(time.time())}\"\n",
    "    wandb.init(\n",
    "        project=\"ddpg-mujoco-benchmark\",\n",
    "        config={\n",
    "            \"env\":env_id,\n",
    "            \"seed\":seed,\n",
    "            \"timesteps\":total_timesteps,\n",
    "            \"lr\":learning_rate,\n",
    "            \"buffer_size\":buffer_size,\n",
    "            \"gamma\":gamma,\n",
    "            \"tau\": tau,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"exploration_noise\":exploration_noise,\n",
    "            \"learning_starts\":learning_starts,\n",
    "            \"policy_frequency\":policy_frequency,\n",
    "            \"noise_clip\":noise_clip,\n",
    "        },\n",
    "        sync_tensorboard=True,\n",
    "        monitor_gym=True,\n",
    "        name=run_name\n",
    "    )\n",
    "    writer = SummaryWriter(f\"runs/{run_name}\")\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    envs = gym.vector.SyncVectorEnv(\n",
    "        [make_env(env_id, seed, 0, True, run_name)]\n",
    "    )\n",
    "\n",
    "    actor = Actor(envs).to(device)\n",
    "    qf1 = QNetwork(envs).to(device)\n",
    "    qf1_target = QNetwork(envs).to(device)\n",
    "    target_actor = Actor(envs).to(device)\n",
    "    target_actor.load_state_dict(actor.state_dict())\n",
    "    qf1_target.load_state_dict(qf1.state_dict())\n",
    "\n",
    "    q_optimizer = optim.Adam(qf1.parameters(), lr=learning_rate)\n",
    "    actor_optimizer = optim.Adam(actor.parameters(), lr=learning_rate)\n",
    "\n",
    "    envs.single_observation_space.dtype = np.float32\n",
    "    rb = ReplayBuffer(\n",
    "        buffer_size,\n",
    "        envs.single_observation_space,\n",
    "        envs.single_action_space,\n",
    "        device,\n",
    "        handle_timeout_termination=False,\n",
    "    )\n",
    "\n",
    "    start_time = time.time()\n",
    "    obs, _ = envs.reset(seed=seed)\n",
    "\n",
    "    for global_step in range(total_timesteps):\n",
    "        if global_step < learning_starts:\n",
    "            actions = np.array([envs.single_action_space.sample() for _ in range(envs.num_envs)])\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                actions = actor(torch.Tensor(obs).to(device))\n",
    "                actions += torch.normal(0, actor.action_scale * exploration_noise)\n",
    "                actions = actions.cpu().numpy().clip(envs.single_action_space.low, envs.single_action_space.high)\n",
    "\n",
    "        next_obs, rewards, terminated, truncated, infos = envs.step(actions)\n",
    "        if \"final_info\" in infos:\n",
    "            for info in infos[\"final_info\"]:\n",
    "                print(f\"global_step={global_step} episodic_return={info['episode']['r']}\")\n",
    "                writer.add_scalar(\"charts/episodic_return\", info[\"episode\"][\"r\"], global_step)\n",
    "                writer.add_scalar(\"charts/episodic_length\", info[\"episode\"][\"l\"], global_step)\n",
    "                break\n",
    "\n",
    "\n",
    "        real_next_obs = next_obs.copy()\n",
    "        for idx,d in enumerate(truncated):\n",
    "            if d:\n",
    "                real_next_obs[idx] = infos[\"final_observation\"][idx]\n",
    "        rb.add(obs, real_next_obs, actions, rewards, terminated, infos)\n",
    "\n",
    "        obs = next_obs\n",
    "\n",
    "        if global_step > learning_starts:\n",
    "            data = rb.sample(batch_size)\n",
    "            with torch.no_grad():\n",
    "                next_state_actions = target_actor(data.next_observations)\n",
    "                qf1_next_target = qf1_target(data.next_observations, next_state_actions)\n",
    "                next_q_value = data.rewards.flatten() + (1 - data.dones.flatten()) * gamma * (qf1_next_target).view(-1)\n",
    "\n",
    "            qf1_a_values = qf1(data.observations, data.actions).view(-1)\n",
    "            qf1_loss = F.mse_loss(qf1_a_values, next_q_value)\n",
    "\n",
    "            q_optimizer.zero_grad()\n",
    "            qf1_loss.backward()\n",
    "            q_optimizer.step()\n",
    "\n",
    "            if global_step % policy_frequency == 0:\n",
    "                actor_loss = -qf1(data.observations, actor(data.observations)).mean()\n",
    "                actor_optimizer.zero_grad()\n",
    "                actor_loss.backward()\n",
    "                actor_optimizer.step()\n",
    "\n",
    "                for param, target_param in zip(actor.parameters(), target_actor.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 -tau) * target_param.data)\n",
    "                for param, target_param in zip(qf1.parameters(), qf1_target.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1 -tau) * target_param.data)\n",
    "\n",
    "            if global_step % 100 == 0:\n",
    "                writer.add_scalar(\"losses/qf1_loss\", qf1_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/actor_loss\", actor_loss.item(), global_step)\n",
    "                writer.add_scalar(\"losses/qf1_values\", qf1_a_values.mean().item(), global_step)\n",
    "                writer.add_scalar(\"charts/SPS\", int(global_step/ (time.time()-start_time)), global_step)\n",
    "\n",
    "    envs.close()\n",
    "    writer.close()\n",
    "    wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-17T09:53:59.451952Z",
     "iopub.status.busy": "2023-11-17T09:53:59.451458Z",
     "iopub.status.idle": "2023-11-17T09:53:59.458661Z",
     "shell.execute_reply": "2023-11-17T09:53:59.457703Z",
     "shell.execute_reply.started": "2023-11-17T09:53:59.451906Z"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1692034397278,
     "user": {
      "displayName": "chhaya kumar das",
      "userId": "05135137199177257776"
     },
     "user_tz": -330
    },
    "id": "_rXtD7-_M5nZ"
   },
   "outputs": [],
   "source": [
    "env = {\"hopper\":\"Hopper-v2\",\"humanoid\":\"Humanoid-v2\",\"halfCheetah\":\"HalfCheetah-v2\",\"ant\":\"Ant-v2\"}\n",
    "seed = 1\n",
    "total_timesteps = 500000\n",
    "learning_rate = 0.00003\n",
    "buffer_size = 100000\n",
    "gamma = 0.99\n",
    "tau = 0.005\n",
    "batch_size = 1024\n",
    "exploration_noise = 0.1\n",
    "learning_starts = 25000\n",
    "policy_frequency = 2\n",
    "noise_clip = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-11-17T09:54:00.903783Z",
     "iopub.status.busy": "2023-11-17T09:54:00.902909Z",
     "iopub.status.idle": "2023-11-17T11:06:21.229445Z",
     "shell.execute_reply": "2023-11-17T11:06:21.228278Z",
     "shell.execute_reply.started": "2023-11-17T09:54:00.903708Z"
    },
    "id": "EO55myBgOAC4",
    "outputId": "9ce8522e-49d6-416d-bd93-03b871c20d6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/rl-algos/wandb/run-20231117_095400-3bfd4kw4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark/runs/3bfd4kw4' target=\"_blank\">Ant-v2__1__1700214840</a></strong> to <a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark' target=\"_blank\">https://wandb.ai/chkda/ddpg-mujoco-benchmark</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark/runs/3bfd4kw4' target=\"_blank\">https://wandb.ai/chkda/ddpg-mujoco-benchmark/runs/3bfd4kw4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/envs/registration.py:523: DeprecationWarning: \u001b[33mWARN: The environment Ant-v2 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/envs/mujoco/mujoco_env.py:185: DeprecationWarning: \u001b[33mWARN: This version of the mujoco environments depends on the mujoco-py bindings, which are no longer maintained and may stop working. Please upgrade to the v4 versions of the environments (which depend on the mujoco python bindings instead), unless you are trying to precisely replicate previous works).\u001b[0m\n",
      "  logger.deprecation(\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method was expecting numpy array dtype to be <class 'numpy.float32'>, actual type: float64\u001b[0m\n",
      "  logger.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/gymnasium/utils/passive_env_checker.py:188: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-0.mp4\n",
      "global_step=160 episodic_return=[42.22905]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-1.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-1.mp4\n",
      "global_step=183 episodic_return=[-17.043615]\n",
      "global_step=257 episodic_return=[-17.401993]\n",
      "global_step=380 episodic_return=[-71.388084]\n",
      "global_step=406 episodic_return=[-26.250313]\n",
      "global_step=476 episodic_return=[-39.342514]\n",
      "global_step=549 episodic_return=[-28.581144]\n",
      "global_step=578 episodic_return=[-8.204443]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-8.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-8.mp4\n",
      "global_step=698 episodic_return=[-53.115475]\n",
      "global_step=717 episodic_return=[-14.89556]\n",
      "global_step=791 episodic_return=[-36.954395]\n",
      "global_step=969 episodic_return=[-106.31509]\n",
      "global_step=1004 episodic_return=[19.458998]\n",
      "global_step=1050 episodic_return=[-50.96988]\n",
      "global_step=1123 episodic_return=[13.090459]\n",
      "global_step=1178 episodic_return=[-21.061117]\n",
      "global_step=1304 episodic_return=[-118.259186]\n",
      "global_step=1358 episodic_return=[-36.142654]\n",
      "global_step=2358 episodic_return=[-362.41718]\n",
      "global_step=2391 episodic_return=[-9.069893]\n",
      "global_step=2467 episodic_return=[-11.695028]\n",
      "global_step=3467 episodic_return=[-243.68365]\n",
      "global_step=3498 episodic_return=[-22.39118]\n",
      "global_step=3517 episodic_return=[-4.254495]\n",
      "global_step=3678 episodic_return=[-89.99716]\n",
      "global_step=3703 episodic_return=[-4.8209853]\n",
      "global_step=3756 episodic_return=[-56.927444]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-27.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-27.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-27.mp4\n",
      "global_step=3785 episodic_return=[-13.862714]\n",
      "global_step=4038 episodic_return=[-58.926765]\n",
      "global_step=5038 episodic_return=[-332.10446]\n",
      "global_step=5079 episodic_return=[-9.97468]\n",
      "global_step=5180 episodic_return=[-12.848262]\n",
      "global_step=5361 episodic_return=[-155.4756]\n",
      "global_step=5447 episodic_return=[-53.692616]\n",
      "global_step=5468 episodic_return=[-18.544811]\n",
      "global_step=5712 episodic_return=[-111.0167]\n",
      "global_step=5880 episodic_return=[-77.27002]\n",
      "global_step=5912 episodic_return=[-8.942126]\n",
      "global_step=5940 episodic_return=[0.28478962]\n",
      "global_step=5970 episodic_return=[-9.997675]\n",
      "global_step=6105 episodic_return=[-51.17861]\n",
      "global_step=6277 episodic_return=[-45.643555]\n",
      "global_step=6291 episodic_return=[7.8121595]\n",
      "global_step=6312 episodic_return=[6.445875]\n",
      "global_step=7312 episodic_return=[-261.16873]\n",
      "global_step=7419 episodic_return=[-53.867752]\n",
      "global_step=7465 episodic_return=[-32.28207]\n",
      "global_step=7529 episodic_return=[-6.932116]\n",
      "global_step=7606 episodic_return=[-65.80188]\n",
      "global_step=7643 episodic_return=[-1.6972778]\n",
      "global_step=7684 episodic_return=[-36.485527]\n",
      "global_step=8684 episodic_return=[-364.3207]\n",
      "global_step=8710 episodic_return=[-13.70464]\n",
      "global_step=8920 episodic_return=[-95.60789]\n",
      "global_step=9003 episodic_return=[-48.617077]\n",
      "global_step=9090 episodic_return=[-18.753654]\n",
      "global_step=9164 episodic_return=[19.28647]\n",
      "global_step=9236 episodic_return=[-50.901558]\n",
      "global_step=9260 episodic_return=[-8.288224]\n",
      "global_step=9301 episodic_return=[-33.049168]\n",
      "global_step=9326 episodic_return=[11.310247]\n",
      "global_step=10326 episodic_return=[-362.69095]\n",
      "global_step=10338 episodic_return=[-5.6681504]\n",
      "global_step=10365 episodic_return=[-3.3009965]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-64.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-64.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-64.mp4\n",
      "global_step=10581 episodic_return=[-96.02093]\n",
      "global_step=10604 episodic_return=[11.243341]\n",
      "global_step=10629 episodic_return=[4.436721]\n",
      "global_step=10678 episodic_return=[-2.8331797]\n",
      "global_step=10719 episodic_return=[19.080238]\n",
      "global_step=10766 episodic_return=[-28.182762]\n",
      "global_step=10778 episodic_return=[1.1352761]\n",
      "global_step=10801 episodic_return=[-33.16514]\n",
      "global_step=11801 episodic_return=[-346.8129]\n",
      "global_step=11818 episodic_return=[1.3003843]\n",
      "global_step=12818 episodic_return=[-324.15768]\n",
      "global_step=12993 episodic_return=[-73.92575]\n",
      "global_step=13073 episodic_return=[-11.169964]\n",
      "global_step=13159 episodic_return=[-56.500404]\n",
      "global_step=13225 episodic_return=[-35.084496]\n",
      "global_step=13360 episodic_return=[13.749632]\n",
      "global_step=13392 episodic_return=[-27.675552]\n",
      "global_step=13525 episodic_return=[-19.427258]\n",
      "global_step=13599 episodic_return=[-22.068495]\n",
      "global_step=13749 episodic_return=[-10.107874]\n",
      "global_step=13775 episodic_return=[-14.00545]\n",
      "global_step=13800 episodic_return=[-23.47366]\n",
      "global_step=13844 episodic_return=[-28.147257]\n",
      "global_step=13909 episodic_return=[-59.761955]\n",
      "global_step=14002 episodic_return=[-51.46156]\n",
      "global_step=15002 episodic_return=[-318.7074]\n",
      "global_step=15038 episodic_return=[-19.744356]\n",
      "global_step=15089 episodic_return=[-33.971684]\n",
      "global_step=15172 episodic_return=[-20.607527]\n",
      "global_step=15257 episodic_return=[12.079171]\n",
      "global_step=15366 episodic_return=[-66.3479]\n",
      "global_step=15484 episodic_return=[-70.092865]\n",
      "global_step=15560 episodic_return=[-39.770657]\n",
      "global_step=15577 episodic_return=[-17.130156]\n",
      "global_step=15753 episodic_return=[-93.013084]\n",
      "global_step=15894 episodic_return=[-61.674824]\n",
      "global_step=16894 episodic_return=[-317.19052]\n",
      "global_step=16905 episodic_return=[-0.20803404]\n",
      "global_step=17905 episodic_return=[-326.08905]\n",
      "global_step=17960 episodic_return=[-15.940993]\n",
      "global_step=17987 episodic_return=[1.818792]\n",
      "global_step=18026 episodic_return=[-25.20245]\n",
      "global_step=19026 episodic_return=[-325.51727]\n",
      "global_step=19130 episodic_return=[-109.02351]\n",
      "global_step=19202 episodic_return=[-29.249804]\n",
      "global_step=19304 episodic_return=[-10.4923]\n",
      "global_step=19392 episodic_return=[-21.33131]\n",
      "global_step=19552 episodic_return=[-24.66089]\n",
      "global_step=19598 episodic_return=[14.579449]\n",
      "global_step=19627 episodic_return=[-16.914198]\n",
      "global_step=19665 episodic_return=[-16.102507]\n",
      "global_step=20665 episodic_return=[-354.36578]\n",
      "global_step=20780 episodic_return=[-43.885117]\n",
      "global_step=20930 episodic_return=[-88.730515]\n",
      "global_step=21019 episodic_return=[-12.597561]\n",
      "global_step=21099 episodic_return=[-50.52414]\n",
      "global_step=21282 episodic_return=[-26.273996]\n",
      "global_step=21395 episodic_return=[-9.020926]\n",
      "global_step=21409 episodic_return=[-1.33107]\n",
      "global_step=21514 episodic_return=[-36.21461]\n",
      "global_step=21660 episodic_return=[-111.266136]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-125.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-125.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-125.mp4\n",
      "global_step=21860 episodic_return=[-73.75164]\n",
      "global_step=21926 episodic_return=[-1.7979362]\n",
      "global_step=21956 episodic_return=[-21.901964]\n",
      "global_step=22037 episodic_return=[-66.11238]\n",
      "global_step=22085 episodic_return=[-17.455462]\n",
      "global_step=22109 episodic_return=[-20.132885]\n",
      "global_step=22230 episodic_return=[19.55769]\n",
      "global_step=22285 episodic_return=[-15.049617]\n",
      "global_step=22358 episodic_return=[-18.241104]\n",
      "global_step=22493 episodic_return=[-44.425224]\n",
      "global_step=22793 episodic_return=[-219.90056]\n",
      "global_step=22929 episodic_return=[-111.831856]\n",
      "global_step=23102 episodic_return=[-81.14573]\n",
      "global_step=23484 episodic_return=[-154.86003]\n",
      "global_step=24015 episodic_return=[-178.98242]\n",
      "global_step=24076 episodic_return=[23.21246]\n",
      "global_step=24150 episodic_return=[-42.5105]\n",
      "global_step=24210 episodic_return=[1.8589053]\n",
      "global_step=24228 episodic_return=[-13.74565]\n",
      "global_step=24264 episodic_return=[-43.045677]\n",
      "global_step=24566 episodic_return=[-81.8164]\n",
      "global_step=24586 episodic_return=[-10.69117]\n",
      "global_step=24644 episodic_return=[-13.356642]\n",
      "global_step=24794 episodic_return=[-48.41421]\n",
      "global_step=24878 episodic_return=[-15.218649]\n",
      "global_step=24904 episodic_return=[11.764166]\n",
      "global_step=24990 episodic_return=[-51.25693]\n",
      "global_step=25990 episodic_return=[74.42398]\n",
      "global_step=26990 episodic_return=[-241.42021]\n",
      "global_step=27990 episodic_return=[482.44977]\n",
      "global_step=28990 episodic_return=[354.25055]\n",
      "global_step=29990 episodic_return=[469.14795]\n",
      "global_step=30990 episodic_return=[547.73474]\n",
      "global_step=31990 episodic_return=[637.0333]\n",
      "global_step=32990 episodic_return=[587.4483]\n",
      "global_step=33990 episodic_return=[589.3041]\n",
      "global_step=34990 episodic_return=[626.7144]\n",
      "global_step=35990 episodic_return=[647.354]\n",
      "global_step=36990 episodic_return=[679.9901]\n",
      "global_step=37990 episodic_return=[671.96356]\n",
      "global_step=38990 episodic_return=[731.2388]\n",
      "global_step=39990 episodic_return=[728.8755]\n",
      "global_step=40990 episodic_return=[721.9118]\n",
      "global_step=41990 episodic_return=[737.73395]\n",
      "global_step=42990 episodic_return=[693.68945]\n",
      "global_step=43990 episodic_return=[698.91266]\n",
      "global_step=44990 episodic_return=[677.2154]\n",
      "global_step=45990 episodic_return=[647.51196]\n",
      "global_step=46990 episodic_return=[546.2795]\n",
      "global_step=47990 episodic_return=[362.35687]\n",
      "global_step=48107 episodic_return=[42.964455]\n",
      "global_step=49107 episodic_return=[463.28836]\n",
      "global_step=50107 episodic_return=[295.22467]\n",
      "global_step=51107 episodic_return=[561.6694]\n",
      "global_step=51994 episodic_return=[414.13235]\n",
      "global_step=52561 episodic_return=[383.9836]\n",
      "global_step=53090 episodic_return=[272.85098]\n",
      "global_step=53426 episodic_return=[79.696495]\n",
      "global_step=54426 episodic_return=[-21.29451]\n",
      "global_step=55426 episodic_return=[223.0832]\n",
      "global_step=56426 episodic_return=[-29.902233]\n",
      "global_step=56716 episodic_return=[76.39328]\n",
      "global_step=57716 episodic_return=[430.1689]\n",
      "global_step=58716 episodic_return=[272.58154]\n",
      "global_step=59716 episodic_return=[126.15242]\n",
      "global_step=59768 episodic_return=[16.778545]\n",
      "global_step=59915 episodic_return=[44.695705]\n",
      "global_step=60915 episodic_return=[302.98523]\n",
      "global_step=61915 episodic_return=[-79.5889]\n",
      "global_step=62157 episodic_return=[78.98164]\n",
      "global_step=62281 episodic_return=[53.948143]\n",
      "global_step=63281 episodic_return=[300.94592]\n",
      "global_step=64281 episodic_return=[245.05382]\n",
      "global_step=65281 episodic_return=[323.9306]\n",
      "global_step=66281 episodic_return=[316.32224]\n",
      "global_step=67281 episodic_return=[244.65256]\n",
      "global_step=67366 episodic_return=[41.14129]\n",
      "global_step=68366 episodic_return=[250.8909]\n",
      "global_step=68859 episodic_return=[117.48337]\n",
      "global_step=69859 episodic_return=[275.59885]\n",
      "global_step=70859 episodic_return=[292.2848]\n",
      "global_step=70918 episodic_return=[46.672016]\n",
      "global_step=71918 episodic_return=[252.08244]\n",
      "global_step=72171 episodic_return=[99.29025]\n",
      "global_step=73171 episodic_return=[299.8434]\n",
      "global_step=73398 episodic_return=[78.69203]\n",
      "global_step=73425 episodic_return=[5.6648135]\n",
      "global_step=74425 episodic_return=[168.20137]\n",
      "global_step=75425 episodic_return=[291.35776]\n",
      "global_step=76425 episodic_return=[265.96997]\n",
      "global_step=77425 episodic_return=[288.2428]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-216.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-216.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-216.mp4\n",
      "global_step=78425 episodic_return=[206.55595]\n",
      "global_step=79425 episodic_return=[294.5092]\n",
      "global_step=80425 episodic_return=[295.05118]\n",
      "global_step=80473 episodic_return=[28.744265]\n",
      "global_step=80552 episodic_return=[-17.93425]\n",
      "global_step=81552 episodic_return=[306.06055]\n",
      "global_step=82217 episodic_return=[142.98799]\n",
      "global_step=83217 episodic_return=[252.85503]\n",
      "global_step=84183 episodic_return=[-8.504642]\n",
      "global_step=85183 episodic_return=[207.7507]\n",
      "global_step=86008 episodic_return=[229.51973]\n",
      "global_step=86105 episodic_return=[31.112091]\n",
      "global_step=87105 episodic_return=[347.949]\n",
      "global_step=88105 episodic_return=[143.34071]\n",
      "global_step=89105 episodic_return=[304.149]\n",
      "global_step=90105 episodic_return=[283.1623]\n",
      "global_step=91105 episodic_return=[341.78552]\n",
      "global_step=92105 episodic_return=[106.03972]\n",
      "global_step=92536 episodic_return=[153.59904]\n",
      "global_step=93536 episodic_return=[191.6558]\n",
      "global_step=94536 episodic_return=[310.15137]\n",
      "global_step=95536 episodic_return=[331.7542]\n",
      "global_step=96536 episodic_return=[364.49612]\n",
      "global_step=97536 episodic_return=[363.97308]\n",
      "global_step=98536 episodic_return=[184.21504]\n",
      "global_step=99536 episodic_return=[252.20535]\n",
      "global_step=100536 episodic_return=[475.18973]\n",
      "global_step=101484 episodic_return=[510.6598]\n",
      "global_step=102069 episodic_return=[175.98495]\n",
      "global_step=103069 episodic_return=[386.34717]\n",
      "global_step=104069 episodic_return=[433.53146]\n",
      "global_step=105069 episodic_return=[642.5536]\n",
      "global_step=106069 episodic_return=[481.82486]\n",
      "global_step=107069 episodic_return=[590.3995]\n",
      "global_step=108069 episodic_return=[500.26477]\n",
      "global_step=109069 episodic_return=[585.72174]\n",
      "global_step=110069 episodic_return=[608.437]\n",
      "global_step=111069 episodic_return=[581.08984]\n",
      "global_step=112069 episodic_return=[694.61053]\n",
      "global_step=112180 episodic_return=[57.226532]\n",
      "global_step=113180 episodic_return=[350.04974]\n",
      "global_step=114180 episodic_return=[445.90176]\n",
      "global_step=115180 episodic_return=[721.1465]\n",
      "global_step=116180 episodic_return=[481.4809]\n",
      "global_step=117180 episodic_return=[740.33734]\n",
      "global_step=118180 episodic_return=[547.09094]\n",
      "global_step=119180 episodic_return=[262.975]\n",
      "global_step=119641 episodic_return=[282.88077]\n",
      "global_step=120641 episodic_return=[548.2907]\n",
      "global_step=121641 episodic_return=[464.88266]\n",
      "global_step=122641 episodic_return=[763.1837]\n",
      "global_step=123641 episodic_return=[654.0789]\n",
      "global_step=124641 episodic_return=[756.6747]\n",
      "global_step=125641 episodic_return=[777.7996]\n",
      "global_step=126641 episodic_return=[592.0323]\n",
      "global_step=127328 episodic_return=[485.98566]\n",
      "global_step=128328 episodic_return=[677.31885]\n",
      "global_step=129328 episodic_return=[654.6873]\n",
      "global_step=130328 episodic_return=[701.961]\n",
      "global_step=131328 episodic_return=[706.03253]\n",
      "global_step=132328 episodic_return=[757.3581]\n",
      "global_step=133328 episodic_return=[757.7173]\n",
      "global_step=134328 episodic_return=[607.9403]\n",
      "global_step=135328 episodic_return=[523.0867]\n",
      "global_step=136328 episodic_return=[455.25125]\n",
      "global_step=137328 episodic_return=[745.33075]\n",
      "global_step=138328 episodic_return=[672.3656]\n",
      "global_step=139328 episodic_return=[672.14624]\n",
      "global_step=140328 episodic_return=[676.10583]\n",
      "global_step=141328 episodic_return=[778.0606]\n",
      "global_step=142328 episodic_return=[423.32233]\n",
      "global_step=143328 episodic_return=[508.7122]\n",
      "global_step=144328 episodic_return=[662.7101]\n",
      "global_step=145328 episodic_return=[862.74536]\n",
      "global_step=145446 episodic_return=[120.16963]\n",
      "global_step=146446 episodic_return=[697.3339]\n",
      "global_step=147446 episodic_return=[856.27905]\n",
      "global_step=148446 episodic_return=[767.69617]\n",
      "global_step=148488 episodic_return=[47.65258]\n",
      "global_step=148519 episodic_return=[40.21429]\n",
      "global_step=149519 episodic_return=[795.4609]\n",
      "global_step=150519 episodic_return=[579.7567]\n",
      "global_step=151519 episodic_return=[672.90735]\n",
      "global_step=152519 episodic_return=[723.98175]\n",
      "global_step=153519 episodic_return=[888.02924]\n",
      "global_step=154519 episodic_return=[923.506]\n",
      "global_step=154790 episodic_return=[198.8679]\n",
      "global_step=155790 episodic_return=[722.4512]\n",
      "global_step=156790 episodic_return=[862.4994]\n",
      "global_step=157790 episodic_return=[694.0731]\n",
      "global_step=158790 episodic_return=[796.47864]\n",
      "global_step=159790 episodic_return=[754.6917]\n",
      "global_step=160790 episodic_return=[769.8769]\n",
      "global_step=161790 episodic_return=[684.3784]\n",
      "global_step=162790 episodic_return=[909.0647]\n",
      "global_step=163790 episodic_return=[920.20166]\n",
      "global_step=164790 episodic_return=[675.3801]\n",
      "global_step=165790 episodic_return=[624.17426]\n",
      "global_step=166790 episodic_return=[644.2078]\n",
      "global_step=167790 episodic_return=[640.2562]\n",
      "global_step=168790 episodic_return=[657.67755]\n",
      "global_step=169790 episodic_return=[721.20874]\n",
      "global_step=170790 episodic_return=[634.9152]\n",
      "global_step=171790 episodic_return=[676.61475]\n",
      "global_step=172790 episodic_return=[662.0045]\n",
      "global_step=173790 episodic_return=[632.484]\n",
      "global_step=174790 episodic_return=[724.3329]\n",
      "global_step=175790 episodic_return=[569.4606]\n",
      "global_step=175805 episodic_return=[11.496802]\n",
      "global_step=176805 episodic_return=[709.9854]\n",
      "global_step=177805 episodic_return=[689.7438]\n",
      "global_step=178805 episodic_return=[796.94495]\n",
      "global_step=178997 episodic_return=[152.6735]\n",
      "global_step=179011 episodic_return=[6.1174407]\n",
      "global_step=180011 episodic_return=[657.29926]\n",
      "global_step=181011 episodic_return=[742.34076]\n",
      "global_step=182011 episodic_return=[868.432]\n",
      "global_step=182536 episodic_return=[407.42017]\n",
      "global_step=183536 episodic_return=[733.9144]\n",
      "global_step=184536 episodic_return=[784.9103]\n",
      "global_step=185536 episodic_return=[779.0238]\n",
      "global_step=186536 episodic_return=[789.1321]\n",
      "global_step=187536 episodic_return=[617.4254]\n",
      "global_step=187551 episodic_return=[16.373339]\n",
      "global_step=188551 episodic_return=[831.7955]\n",
      "global_step=188687 episodic_return=[174.10269]\n",
      "global_step=189687 episodic_return=[734.7721]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-343.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-343.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-343.mp4\n",
      "global_step=190687 episodic_return=[713.0635]\n",
      "global_step=191687 episodic_return=[770.29004]\n",
      "global_step=192687 episodic_return=[612.95074]\n",
      "global_step=193392 episodic_return=[735.97705]\n",
      "global_step=194392 episodic_return=[788.5051]\n",
      "global_step=195392 episodic_return=[717.4016]\n",
      "global_step=195459 episodic_return=[80.034164]\n",
      "global_step=196459 episodic_return=[691.00555]\n",
      "global_step=197459 episodic_return=[853.1036]\n",
      "global_step=198459 episodic_return=[891.38586]\n",
      "global_step=198791 episodic_return=[346.4313]\n",
      "global_step=198861 episodic_return=[73.29126]\n",
      "global_step=199861 episodic_return=[712.89185]\n",
      "global_step=200861 episodic_return=[710.7774]\n",
      "global_step=201861 episodic_return=[864.56177]\n",
      "global_step=202227 episodic_return=[432.75598]\n",
      "global_step=203227 episodic_return=[640.1133]\n",
      "global_step=204227 episodic_return=[1261.6677]\n",
      "global_step=205227 episodic_return=[712.13055]\n",
      "global_step=205846 episodic_return=[786.82385]\n",
      "global_step=206846 episodic_return=[1163.2595]\n",
      "global_step=207846 episodic_return=[681.4489]\n",
      "global_step=208846 episodic_return=[1209.5074]\n",
      "global_step=209301 episodic_return=[553.96985]\n",
      "global_step=209882 episodic_return=[731.92535]\n",
      "global_step=210882 episodic_return=[883.98926]\n",
      "global_step=211335 episodic_return=[538.0481]\n",
      "global_step=212335 episodic_return=[897.4619]\n",
      "global_step=213335 episodic_return=[1061.0259]\n",
      "global_step=213552 episodic_return=[329.26312]\n",
      "global_step=214552 episodic_return=[1101.6366]\n",
      "global_step=215552 episodic_return=[1249.2828]\n",
      "global_step=216552 episodic_return=[837.95776]\n",
      "global_step=216697 episodic_return=[218.77847]\n",
      "global_step=217697 episodic_return=[987.6934]\n",
      "global_step=218697 episodic_return=[1176.3733]\n",
      "global_step=219697 episodic_return=[967.0613]\n",
      "global_step=220697 episodic_return=[1385.7772]\n",
      "global_step=221697 episodic_return=[770.76154]\n",
      "global_step=222697 episodic_return=[1024.6266]\n",
      "global_step=223697 episodic_return=[719.41425]\n",
      "global_step=223923 episodic_return=[321.65472]\n",
      "global_step=224923 episodic_return=[1073.6211]\n",
      "global_step=225167 episodic_return=[304.6659]\n",
      "global_step=226167 episodic_return=[784.0677]\n",
      "global_step=227167 episodic_return=[729.4932]\n",
      "global_step=227687 episodic_return=[808.41174]\n",
      "global_step=228687 episodic_return=[992.5702]\n",
      "global_step=229348 episodic_return=[919.40216]\n",
      "global_step=229597 episodic_return=[355.34848]\n",
      "global_step=230555 episodic_return=[1379.144]\n",
      "global_step=230719 episodic_return=[254.90707]\n",
      "global_step=230880 episodic_return=[190.52365]\n",
      "global_step=231880 episodic_return=[664.34467]\n",
      "global_step=232880 episodic_return=[660.7725]\n",
      "global_step=233880 episodic_return=[704.6331]\n",
      "global_step=234880 episodic_return=[824.5223]\n",
      "global_step=235880 episodic_return=[820.78345]\n",
      "global_step=236880 episodic_return=[1562.6887]\n",
      "global_step=237880 episodic_return=[937.1817]\n",
      "global_step=238880 episodic_return=[1548.7549]\n",
      "global_step=239880 episodic_return=[1262.2461]\n",
      "global_step=240880 episodic_return=[1144.185]\n",
      "global_step=241880 episodic_return=[1212.5887]\n",
      "global_step=242132 episodic_return=[372.64838]\n",
      "global_step=243132 episodic_return=[1547.0189]\n",
      "global_step=244132 episodic_return=[1676.0763]\n",
      "global_step=245132 episodic_return=[1522.204]\n",
      "global_step=246132 episodic_return=[1652.7599]\n",
      "global_step=247132 episodic_return=[1608.7443]\n",
      "global_step=248058 episodic_return=[1370.5833]\n",
      "global_step=249058 episodic_return=[735.91565]\n",
      "global_step=250058 episodic_return=[1674.4153]\n",
      "global_step=251058 episodic_return=[1091.305]\n",
      "global_step=252058 episodic_return=[1613.7238]\n",
      "global_step=252642 episodic_return=[955.02826]\n",
      "global_step=253642 episodic_return=[1366.31]\n",
      "global_step=254642 episodic_return=[798.5529]\n",
      "global_step=255642 episodic_return=[1482.5128]\n",
      "global_step=256642 episodic_return=[1588.0786]\n",
      "global_step=257642 episodic_return=[575.7345]\n",
      "global_step=258642 episodic_return=[1615.7756]\n",
      "global_step=259642 episodic_return=[1055.9407]\n",
      "global_step=260642 episodic_return=[1857.9968]\n",
      "global_step=260853 episodic_return=[354.1182]\n",
      "global_step=261853 episodic_return=[1531.5536]\n",
      "global_step=262853 episodic_return=[1257.8104]\n",
      "global_step=263853 episodic_return=[972.64496]\n",
      "global_step=264853 episodic_return=[1842.4059]\n",
      "global_step=265853 episodic_return=[1954.6]\n",
      "global_step=266853 episodic_return=[1098.9182]\n",
      "global_step=267853 episodic_return=[1870.3071]\n",
      "global_step=268853 episodic_return=[2021.3859]\n",
      "global_step=269853 episodic_return=[1909.3997]\n",
      "global_step=270853 episodic_return=[311.00006]\n",
      "global_step=271400 episodic_return=[983.27795]\n",
      "global_step=272400 episodic_return=[962.6355]\n",
      "global_step=273400 episodic_return=[1979.5088]\n",
      "global_step=274400 episodic_return=[1880.6008]\n",
      "global_step=275400 episodic_return=[959.4955]\n",
      "global_step=276400 episodic_return=[1103.7719]\n",
      "global_step=277400 episodic_return=[1216.1616]\n",
      "global_step=278400 episodic_return=[712.95935]\n",
      "global_step=278835 episodic_return=[761.4589]\n",
      "global_step=279835 episodic_return=[1838.2692]\n",
      "global_step=280344 episodic_return=[1003.0169]\n",
      "global_step=281344 episodic_return=[833.10535]\n",
      "global_step=282344 episodic_return=[1154.2118]\n",
      "global_step=283344 episodic_return=[1941.276]\n",
      "global_step=284344 episodic_return=[831.39166]\n",
      "global_step=285344 episodic_return=[1037.0928]\n",
      "global_step=286344 episodic_return=[1556.804]\n",
      "global_step=287344 episodic_return=[894.89923]\n",
      "global_step=288344 episodic_return=[955.715]\n",
      "global_step=289344 episodic_return=[2006.9684]\n",
      "global_step=290344 episodic_return=[973.9382]\n",
      "global_step=291344 episodic_return=[541.9235]\n",
      "global_step=292344 episodic_return=[1827.9604]\n",
      "global_step=293344 episodic_return=[1261.7218]\n",
      "global_step=294344 episodic_return=[886.91754]\n",
      "global_step=294489 episodic_return=[186.59271]\n",
      "global_step=295489 episodic_return=[814.12177]\n",
      "global_step=296489 episodic_return=[582.5484]\n",
      "global_step=296661 episodic_return=[403.5386]\n",
      "global_step=297341 episodic_return=[1314.7681]\n",
      "global_step=298341 episodic_return=[664.11115]\n",
      "global_step=299341 episodic_return=[712.08057]\n",
      "global_step=300341 episodic_return=[1976.9384]\n",
      "global_step=300403 episodic_return=[138.96713]\n",
      "global_step=300678 episodic_return=[503.20792]\n",
      "global_step=301678 episodic_return=[2114.1084]\n",
      "global_step=302466 episodic_return=[1657.4633]\n",
      "global_step=302618 episodic_return=[266.4789]\n",
      "global_step=303618 episodic_return=[2157.98]\n",
      "global_step=304618 episodic_return=[798.62036]\n",
      "global_step=305618 episodic_return=[999.07214]\n",
      "global_step=306618 episodic_return=[2123.7417]\n",
      "global_step=307618 episodic_return=[887.35333]\n",
      "global_step=308618 episodic_return=[675.598]\n",
      "global_step=309618 episodic_return=[2160.2573]\n",
      "global_step=310618 episodic_return=[1183.8898]\n",
      "global_step=311618 episodic_return=[883.2215]\n",
      "global_step=312618 episodic_return=[2085.5974]\n",
      "global_step=312819 episodic_return=[399.31152]\n",
      "global_step=313819 episodic_return=[2038.7712]\n",
      "global_step=314819 episodic_return=[1029.3939]\n",
      "global_step=315819 episodic_return=[2030.8307]\n",
      "global_step=316819 episodic_return=[2140.7979]\n",
      "global_step=317146 episodic_return=[678.03394]\n",
      "global_step=318146 episodic_return=[2140.0916]\n",
      "global_step=319146 episodic_return=[751.2259]\n",
      "global_step=319774 episodic_return=[1338.9911]\n",
      "global_step=320264 episodic_return=[1001.1537]\n",
      "global_step=321264 episodic_return=[772.552]\n",
      "global_step=322264 episodic_return=[2023.3011]\n",
      "global_step=323264 episodic_return=[1382.4846]\n",
      "global_step=323755 episodic_return=[1132.6133]\n",
      "global_step=324755 episodic_return=[1120.0931]\n",
      "global_step=325584 episodic_return=[1843.3129]\n",
      "global_step=326584 episodic_return=[2253.5906]\n",
      "global_step=327584 episodic_return=[1923.5923]\n",
      "global_step=328584 episodic_return=[602.5105]\n",
      "global_step=329584 episodic_return=[1472.7568]\n",
      "global_step=330584 episodic_return=[2329.0464]\n",
      "global_step=331584 episodic_return=[2330.4246]\n",
      "global_step=332584 episodic_return=[1605.9231]\n",
      "global_step=332604 episodic_return=[35.003704]\n",
      "global_step=333604 episodic_return=[2258.8633]\n",
      "global_step=334604 episodic_return=[2077.127]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-512.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-512.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-512.mp4\n",
      "global_step=335604 episodic_return=[2134.5283]\n",
      "global_step=336604 episodic_return=[762.4864]\n",
      "global_step=337604 episodic_return=[815.12274]\n",
      "global_step=338101 episodic_return=[1081.8219]\n",
      "global_step=338113 episodic_return=[14.80005]\n",
      "global_step=339091 episodic_return=[2260.2322]\n",
      "global_step=339510 episodic_return=[968.3751]\n",
      "global_step=340510 episodic_return=[725.63293]\n",
      "global_step=341510 episodic_return=[2236.2727]\n",
      "global_step=342510 episodic_return=[1294.0114]\n",
      "global_step=343090 episodic_return=[1142.8048]\n",
      "global_step=343713 episodic_return=[1494.1022]\n",
      "global_step=344713 episodic_return=[2130.2598]\n",
      "global_step=345713 episodic_return=[2048.7927]\n",
      "global_step=346713 episodic_return=[2084.0037]\n",
      "global_step=346772 episodic_return=[106.34516]\n",
      "global_step=347772 episodic_return=[2272.9346]\n",
      "global_step=348772 episodic_return=[1191.8914]\n",
      "global_step=349772 episodic_return=[2153.6062]\n",
      "global_step=350772 episodic_return=[1610.078]\n",
      "global_step=351772 episodic_return=[2047.4917]\n",
      "global_step=352772 episodic_return=[2080.9636]\n",
      "global_step=353772 episodic_return=[1757.4204]\n",
      "global_step=354165 episodic_return=[842.98065]\n",
      "global_step=354275 episodic_return=[228.40756]\n",
      "global_step=355275 episodic_return=[1882.8997]\n",
      "global_step=356041 episodic_return=[1677.0863]\n",
      "global_step=357041 episodic_return=[313.979]\n",
      "global_step=358041 episodic_return=[2443.3423]\n",
      "global_step=359041 episodic_return=[2245.5952]\n",
      "global_step=360041 episodic_return=[2202.6304]\n",
      "global_step=361041 episodic_return=[437.17282]\n",
      "global_step=361268 episodic_return=[478.55234]\n",
      "global_step=361972 episodic_return=[1597.875]\n",
      "global_step=362534 episodic_return=[1298.5072]\n",
      "global_step=362582 episodic_return=[97.81057]\n",
      "global_step=363582 episodic_return=[2080.6882]\n",
      "global_step=364582 episodic_return=[642.9635]\n",
      "global_step=364680 episodic_return=[213.72723]\n",
      "global_step=365680 episodic_return=[2356.2756]\n",
      "global_step=366680 episodic_return=[855.4889]\n",
      "global_step=367680 episodic_return=[1839.0331]\n",
      "global_step=368680 episodic_return=[2344.1409]\n",
      "global_step=369680 episodic_return=[2353.6606]\n",
      "global_step=370211 episodic_return=[1145.7695]\n",
      "global_step=370472 episodic_return=[506.3342]\n",
      "global_step=371061 episodic_return=[1321.513]\n",
      "global_step=372061 episodic_return=[2075.1692]\n",
      "global_step=373061 episodic_return=[2277.187]\n",
      "global_step=374061 episodic_return=[525.0294]\n",
      "global_step=375061 episodic_return=[474.19058]\n",
      "global_step=376061 episodic_return=[1151.9868]\n",
      "global_step=377061 episodic_return=[2098.5354]\n",
      "global_step=377352 episodic_return=[605.25275]\n",
      "global_step=378352 episodic_return=[2110.245]\n",
      "global_step=379352 episodic_return=[2246.7922]\n",
      "global_step=380352 episodic_return=[816.294]\n",
      "global_step=380938 episodic_return=[1387.7838]\n",
      "global_step=381938 episodic_return=[1844.8365]\n",
      "global_step=382938 episodic_return=[2289.5417]\n",
      "global_step=383938 episodic_return=[1903.364]\n",
      "global_step=384412 episodic_return=[1070.92]\n",
      "global_step=385412 episodic_return=[599.4881]\n",
      "global_step=386059 episodic_return=[1459.8524]\n",
      "global_step=387059 episodic_return=[2289.6328]\n",
      "global_step=388059 episodic_return=[1358.4142]\n",
      "global_step=388613 episodic_return=[1270.977]\n",
      "global_step=388805 episodic_return=[401.38638]\n",
      "global_step=389805 episodic_return=[2400.5208]\n",
      "global_step=390805 episodic_return=[1102.6715]\n",
      "global_step=391277 episodic_return=[1109.8309]\n",
      "global_step=392277 episodic_return=[2297.594]\n",
      "global_step=393277 episodic_return=[2378.5366]\n",
      "global_step=393350 episodic_return=[128.39049]\n",
      "global_step=394005 episodic_return=[1473.9961]\n",
      "global_step=394126 episodic_return=[318.35245]\n",
      "global_step=394194 episodic_return=[147.02765]\n",
      "global_step=395194 episodic_return=[2223.5835]\n",
      "global_step=395770 episodic_return=[1213.644]\n",
      "global_step=396770 episodic_return=[2069.5063]\n",
      "global_step=397419 episodic_return=[1440.9979]\n",
      "global_step=397873 episodic_return=[1105.828]\n",
      "global_step=398873 episodic_return=[2229.237]\n",
      "global_step=398989 episodic_return=[285.1195]\n",
      "global_step=399331 episodic_return=[784.095]\n",
      "global_step=400331 episodic_return=[2263.0686]\n",
      "global_step=400761 episodic_return=[955.6496]\n",
      "global_step=401761 episodic_return=[765.0988]\n",
      "global_step=401809 episodic_return=[92.84415]\n",
      "global_step=402809 episodic_return=[2456.9353]\n",
      "global_step=403120 episodic_return=[733.4002]\n",
      "global_step=404120 episodic_return=[1901.6881]\n",
      "global_step=405008 episodic_return=[2072.1848]\n",
      "global_step=406008 episodic_return=[2253.7632]\n",
      "global_step=407008 episodic_return=[2246.0762]\n",
      "global_step=408008 episodic_return=[1777.2207]\n",
      "global_step=409008 episodic_return=[2239.965]\n",
      "global_step=410008 episodic_return=[718.16235]\n",
      "global_step=410420 episodic_return=[893.49304]\n",
      "global_step=411420 episodic_return=[1670.4615]\n",
      "global_step=412420 episodic_return=[2266.2559]\n",
      "global_step=413303 episodic_return=[2030.8452]\n",
      "global_step=414256 episodic_return=[2249.5942]\n",
      "global_step=414932 episodic_return=[1513.7029]\n",
      "global_step=415022 episodic_return=[172.21507]\n",
      "global_step=415170 episodic_return=[364.47202]\n",
      "global_step=416170 episodic_return=[1402.8203]\n",
      "global_step=416351 episodic_return=[416.4872]\n",
      "global_step=416895 episodic_return=[1357.586]\n",
      "global_step=417895 episodic_return=[1441.8439]\n",
      "global_step=418895 episodic_return=[2162.3628]\n",
      "global_step=419895 episodic_return=[1625.2837]\n",
      "global_step=420895 episodic_return=[2344.724]\n",
      "global_step=421895 episodic_return=[1140.7335]\n",
      "global_step=422895 episodic_return=[764.972]\n",
      "global_step=423479 episodic_return=[1256.4572]\n",
      "global_step=424479 episodic_return=[2240.7625]\n",
      "global_step=425479 episodic_return=[191.3851]\n",
      "global_step=426479 episodic_return=[2257.8228]\n",
      "global_step=426666 episodic_return=[459.37207]\n",
      "global_step=427628 episodic_return=[2147.6711]\n",
      "global_step=428628 episodic_return=[1707.8549]\n",
      "global_step=429147 episodic_return=[1221.802]\n",
      "global_step=429613 episodic_return=[1053.0536]\n",
      "global_step=430613 episodic_return=[1864.11]\n",
      "global_step=431613 episodic_return=[2343.8835]\n",
      "global_step=432063 episodic_return=[950.1158]\n",
      "global_step=432463 episodic_return=[1045.3165]\n",
      "global_step=433238 episodic_return=[1871.5355]\n",
      "global_step=434238 episodic_return=[243.07089]\n",
      "global_step=435238 episodic_return=[2088.809]\n",
      "global_step=435734 episodic_return=[1143.2036]\n",
      "global_step=436196 episodic_return=[1044.9884]\n",
      "global_step=437196 episodic_return=[1083.9542]\n",
      "global_step=437291 episodic_return=[213.59406]\n",
      "global_step=438291 episodic_return=[2251.953]\n",
      "global_step=438376 episodic_return=[194.41057]\n",
      "global_step=438462 episodic_return=[189.61746]\n",
      "global_step=439035 episodic_return=[1231.513]\n",
      "global_step=440035 episodic_return=[2515.373]\n",
      "global_step=441035 episodic_return=[410.33197]\n",
      "global_step=441194 episodic_return=[376.45874]\n",
      "global_step=442194 episodic_return=[2300.258]\n",
      "global_step=443194 episodic_return=[778.9541]\n",
      "global_step=443403 episodic_return=[477.70554]\n",
      "global_step=444106 episodic_return=[1578.6722]\n",
      "global_step=444799 episodic_return=[1563.3842]\n",
      "global_step=445799 episodic_return=[1209.8893]\n",
      "global_step=446799 episodic_return=[2243.6636]\n",
      "global_step=447295 episodic_return=[1166.3522]\n",
      "global_step=447371 episodic_return=[150.65288]\n",
      "global_step=448371 episodic_return=[84.551155]\n",
      "global_step=449371 episodic_return=[2480.788]\n",
      "global_step=449593 episodic_return=[521.7329]\n",
      "global_step=450593 episodic_return=[2458.1963]\n",
      "global_step=450774 episodic_return=[419.27457]\n",
      "global_step=451774 episodic_return=[1682.506]\n",
      "global_step=452774 episodic_return=[538.4826]\n",
      "global_step=453461 episodic_return=[1632.1754]\n",
      "global_step=453626 episodic_return=[379.22678]\n",
      "global_step=454626 episodic_return=[2521.5356]\n",
      "global_step=454877 episodic_return=[651.2717]\n",
      "global_step=455201 episodic_return=[761.77716]\n",
      "global_step=456201 episodic_return=[2390.8884]\n",
      "global_step=457201 episodic_return=[1465.9263]\n",
      "global_step=457458 episodic_return=[504.99417]\n",
      "global_step=458458 episodic_return=[2707.0212]\n",
      "global_step=459458 episodic_return=[1184.899]\n",
      "global_step=459552 episodic_return=[265.83124]\n",
      "global_step=460552 episodic_return=[2619.9058]\n",
      "global_step=461381 episodic_return=[2022.8481]\n",
      "global_step=462381 episodic_return=[2513.2708]\n",
      "global_step=463381 episodic_return=[-321.95844]\n",
      "global_step=464381 episodic_return=[1103.0742]\n",
      "global_step=465381 episodic_return=[2534.8445]\n",
      "global_step=465995 episodic_return=[1575.8552]\n",
      "global_step=466995 episodic_return=[2365.0308]\n",
      "global_step=467967 episodic_return=[2512.065]\n",
      "global_step=468014 episodic_return=[95.308136]\n",
      "global_step=469014 episodic_return=[1278.7358]\n",
      "global_step=469182 episodic_return=[379.88116]\n",
      "global_step=469983 episodic_return=[1997.8171]\n",
      "global_step=470153 episodic_return=[439.2228]\n",
      "global_step=471153 episodic_return=[717.287]\n",
      "global_step=471439 episodic_return=[706.1878]\n",
      "global_step=472439 episodic_return=[1541.6294]\n",
      "global_step=472753 episodic_return=[798.6393]\n",
      "global_step=473753 episodic_return=[2714.3774]\n",
      "global_step=474244 episodic_return=[1227.4276]\n",
      "global_step=474308 episodic_return=[150.28741]\n",
      "global_step=474398 episodic_return=[147.61139]\n",
      "global_step=475398 episodic_return=[2533.7417]\n",
      "global_step=476398 episodic_return=[711.7094]\n",
      "global_step=476549 episodic_return=[352.65897]\n",
      "global_step=477458 episodic_return=[2360.7383]\n",
      "global_step=478357 episodic_return=[2168.023]\n",
      "global_step=478706 episodic_return=[909.9704]\n",
      "global_step=478761 episodic_return=[114.94496]\n",
      "global_step=479761 episodic_return=[2605.95]\n",
      "global_step=480761 episodic_return=[1365.7043]\n",
      "global_step=481395 episodic_return=[1646.923]\n",
      "global_step=482395 episodic_return=[2294.3174]\n",
      "global_step=483395 episodic_return=[580.9923]\n",
      "global_step=484395 episodic_return=[2669.9956]\n",
      "global_step=485395 episodic_return=[2624.614]\n",
      "global_step=485921 episodic_return=[1310.3091]\n",
      "global_step=486921 episodic_return=[-106.11234]\n",
      "global_step=487921 episodic_return=[1549.2351]\n",
      "global_step=488921 episodic_return=[2629.9866]\n",
      "global_step=489921 episodic_return=[2648.222]\n",
      "global_step=490921 episodic_return=[2523.2454]\n",
      "global_step=491623 episodic_return=[1854.8992]\n",
      "global_step=492399 episodic_return=[1991.3837]\n",
      "global_step=492842 episodic_return=[1251.3961]\n",
      "global_step=493842 episodic_return=[726.7882]\n",
      "global_step=494842 episodic_return=[203.93701]\n",
      "global_step=495842 episodic_return=[888.7077]\n",
      "Moviepy - Building video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-729.mp4.\n",
      "Moviepy - Writing video /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-729.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /notebooks/rl-algos/videos/Ant-v2__1__1700214840/rl-video-episode-729.mp4\n",
      "global_step=496031 episodic_return=[307.95984]\n",
      "global_step=496077 episodic_return=[75.84446]\n",
      "global_step=496665 episodic_return=[1584.9948]\n",
      "global_step=496974 episodic_return=[767.0973]\n",
      "global_step=497741 episodic_return=[1624.9625]\n",
      "global_step=498741 episodic_return=[1108.1196]\n",
      "global_step=498778 episodic_return=[66.428825]\n",
      "global_step=498821 episodic_return=[123.496284]\n",
      "global_step=499009 episodic_return=[513.6162]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87fc251d598445aa2158b7e315c4bad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='10.941 MB of 10.941 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>charts/SPS</td><td></td></tr><tr><td>charts/episodic_length</td><td></td></tr><tr><td>charts/episodic_return</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>losses/actor_loss</td><td></td></tr><tr><td>losses/qf1_loss</td><td></td></tr><tr><td>losses/qf1_values</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>charts/SPS</td><td>115.0</td></tr><tr><td>charts/episodic_length</td><td>188.0</td></tr><tr><td>charts/episodic_return</td><td>513.61621</td></tr><tr><td>global_step</td><td>499900</td></tr><tr><td>losses/actor_loss</td><td>-260.11719</td></tr><tr><td>losses/qf1_loss</td><td>9.44849</td></tr><tr><td>losses/qf1_values</td><td>259.00995</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Ant-v2__1__1700214840</strong> at: <a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark/runs/3bfd4kw4' target=\"_blank\">https://wandb.ai/chkda/ddpg-mujoco-benchmark/runs/3bfd4kw4</a><br/> View job at <a href='https://wandb.ai/chkda/ddpg-mujoco-benchmark/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNjU2NDQ1NA==/version_details/v3' target=\"_blank\">https://wandb.ai/chkda/ddpg-mujoco-benchmark/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExNjU2NDQ1NA==/version_details/v3</a><br/>Synced 5 W&B file(s), 10 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231117_095400-3bfd4kw4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train(env[\"hopper\"],seed, total_timesteps,\n",
    "      learning_rate, buffer_size, gamma, tau, batch_size,\n",
    "      exploration_noise,learning_starts,\n",
    "      policy_frequency,noise_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMC7/8B5EumW5pGbVPeN7qr",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
